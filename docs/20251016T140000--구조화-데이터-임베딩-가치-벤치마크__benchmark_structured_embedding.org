* ğŸ¯ êµ¬ì¡°í™” ë°ì´í„° ì„ë² ë”© ê°€ì¹˜ ë²¤ì¹˜ë§ˆí¬: "ìµœì†Œ ë…¸ë ¥, ìµœëŒ€ íš¨ê³¼"
:PROPERTIES:
:CUSTOM_ID: êµ¬ì¡°í™”-ë°ì´í„°-ì„ë² ë”©-ê°€ì¹˜-ë²¤ì¹˜ë§ˆí¬-ìµœì†Œ-ë…¸ë ¥-ìµœëŒ€-íš¨ê³¼
:END:
*í•µì‹¬ ì§ˆë¬¸*: > "ì¸ê°„ì´ ìµœì†Œí•œì˜ ë…¸ë ¥ìœ¼ë¡œ í•˜ëŠ” êµ¬ì¡°í™” (Denote, Org
heading, FILETAGS, í´ë”)ê°€ > ì„ë² ë”©ê³¼ RAG í’ˆì§ˆì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ê°€?"

*ê°€ì„¤*:

#+begin_example
ì¸ê°„ ì¹œí™”ì  êµ¬ì¡°í™” = AI ì¹œí™”ì 

Denote íŒŒì¼ëª… (timestamp--í•œê¸€ì œëª©__ì˜ì–´íƒœê·¸)
    â†’ íŒŒì‹± ê°€ëŠ¥, ë©”íƒ€ë°ì´í„° í’ë¶€
    â†’ ì„ë² ë”© í’ˆì§ˆ í–¥ìƒ

Org heading (*, **, ***)
    â†’ ê³„ì¸µ êµ¬ì¡°, ì˜ë¯¸ ë‹¨ìœ„
    â†’ ì²­í‚¹ í’ˆì§ˆ í–¥ìƒ

FILETAGS (:tag1:tag2:)
    â†’ ì»¨í…ìŠ¤íŠ¸ ëª…í™•
    â†’ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ

í´ë” êµ¬ì¡° (meta, bib, journal, notes)
    â†’ ì§€ì‹ ê³„ì¸µ
    â†’ RAG ë‹µë³€ í’ˆì§ˆ í–¥ìƒ
#+end_example

*ì¸¡ì • ëª©í‘œ*:

#+begin_example
ë¹„êµ¬ì¡°í™” (ì¼ë°˜ íŒŒì¼ëª…, flat text)
    vs
êµ¬ì¡°í™” (Denote + Org + FILETAGS + í´ë”)
    â†’
í’ˆì§ˆ ì°¨ì´ = êµ¬ì¡°í™”ì˜ ê°€ì¹˜!
#+end_example

--------------

** ğŸ“Š ê¸°ì¡´ ì„ë² ë”© ë²¤ì¹˜ë§ˆí¬ (MTEB/BEIR)
:PROPERTIES:
:CUSTOM_ID: ê¸°ì¡´-ì„ë² ë”©-ë²¤ì¹˜ë§ˆí¬-mtebbeir
:END:
*** MTEB (Massive Text Embedding Benchmark)
:PROPERTIES:
:CUSTOM_ID: mteb-massive-text-embedding-benchmark
:END:
*ê·œëª¨*:

#+begin_src yaml
Datasets: 58ê°œ
Languages: 112ê°œ
Tasks: 8ê°€ì§€
  - Retrieval (ê²€ìƒ‰)
  - STS (ì˜ë¯¸ ìœ ì‚¬ë„)
  - Classification (ë¶„ë¥˜)
  - Clustering (êµ°ì§‘í™”)
  - Reranking (ì¬ìˆœìœ„)
  - Summarization (ìš”ì•½)
  - Bitext Mining (ì´ì¤‘ í…ìŠ¤íŠ¸)
  - Pair Classification (ìŒ ë¶„ë¥˜)
#+end_src

*Retrieval Metrics*:

#+begin_src python
nDCG@10 (Normalized Discounted Cumulative Gain)
MRR@10 (Mean Reciprocal Rank)
MAP@10 (Mean Average Precision)
Recall@10
Precision@10
#+end_src

*BEIR ë°ì´í„°ì…‹* (18ê°œ): - MS MARCO, TREC-COVID, Natural Questions -
HotpotQA, FiQA, ArguAna, TouchÃ©-2020 - CQADupStack, Quora, DBPedia,
SCIDOCS - FEVER, Climate-FEVER, SciFact, ...

--------------

*** RAG Evaluation Metrics
:PROPERTIES:
:CUSTOM_ID: rag-evaluation-metrics
:END:
*ê²€ìƒ‰ í’ˆì§ˆ* (Retrieval):

#+begin_src python
MRR (Mean Reciprocal Rank):
  # ì •ë‹µì´ ëª‡ ë²ˆì§¸ì— ë‚˜ì˜¤ëŠ”ê°€?
  # 1ìœ„: 1.0, 2ìœ„: 0.5, 3ìœ„: 0.33...
  # ë¹ ë¥¸ ì •ë‹µ ë°œê²¬ ì¸¡ì •

NDCG@k (Normalized DCG):
  # ìˆœìœ„ë³„ ê°€ì¤‘ì¹˜ (ìƒìœ„ì¼ìˆ˜ë¡ ì¤‘ìš”)
  # ë‹¤ì¤‘ ì •ë‹µì˜ ìˆœìœ„ í’ˆì§ˆ

Recall@k:
  # ì „ì²´ ì •ë‹µ ì¤‘ kê°œ ì•ˆì— ëª‡ ê°œ?
  # ì •ë‹µ ë†“ì¹˜ì§€ ì•ŠëŠ”ì§€ ì¸¡ì •

Precision@k:
  # kê°œ ì¤‘ ì •ë‹µ ë¹„ìœ¨
  # ë…¸ì´ì¦ˆ ì–¼ë§ˆë‚˜ ì ì€ì§€
#+end_src

*RAG ë‹µë³€ í’ˆì§ˆ* (Generation):

#+begin_src python
Faithfulness:
  # ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì— ê¸°ë°˜í–ˆëŠ”ê°€?

Answer Relevancy:
  # ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ê°€?

Context Precision:
  # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì •í™•í•œê°€?

Context Recall:
  # í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë‹¤ ê°€ì ¸ì™”ëŠ”ê°€?
#+end_src

--------------

** ğŸ§ª êµ¬ì¡°í™” ê°€ì¹˜ ì¸¡ì • ë²¤ì¹˜ë§ˆí¬ ì„¤ê³„
:PROPERTIES:
:CUSTOM_ID: êµ¬ì¡°í™”-ê°€ì¹˜-ì¸¡ì •-ë²¤ì¹˜ë§ˆí¬-ì„¤ê³„
:END:
*** í•µì‹¬ ì•„ì´ë””ì–´: "ë‹¨ê³„ì  êµ¬ì¡°í™”"
:PROPERTIES:
:CUSTOM_ID: í•µì‹¬-ì•„ì´ë””ì–´-ë‹¨ê³„ì -êµ¬ì¡°í™”
:END:
*ë¹„êµêµ° ì„¤ê³„* (Aâ†’E, ë‹¨ê³„ì  êµ¬ì¡° ì¶”ê°€):

#+begin_src yaml
Aì¡° (ë¹„êµ¬ì¡°í™”):
  íŒŒì¼ëª…: "doc001.md", "doc002.md", "doc003.md"
  ë‚´ìš©: flat markdown (heading ì—†ìŒ)
  íƒœê·¸: ì—†ìŒ
  í´ë”: ë‹¨ì¼ ë””ë ‰í† ë¦¬

Bì¡° (Denote íŒŒì¼ëª…ë§Œ):
  íŒŒì¼ëª…: "20250101T120000--ë¨¸ì‹ ëŸ¬ë‹-ê°œë…__ml_ai.md"
  ë‚´ìš©: flat markdown (ë™ì¼)
  íƒœê·¸: íŒŒì¼ëª…ì—ë§Œ (ml, ai)
  í´ë”: ë‹¨ì¼ ë””ë ‰í† ë¦¬

Cì¡° (+ Markdown Heading):
  íŒŒì¼ëª…: Denote (Bì¡°ì™€ ë™ì¼)
  ë‚´ìš©: # Heading, ## Subheading êµ¬ì¡°í™”
  íƒœê·¸: íŒŒì¼ëª… (Bì¡°ì™€ ë™ì¼)
  í´ë”: ë‹¨ì¼ ë””ë ‰í† ë¦¬

Dì¡° (+ Frontmatter tags):
  íŒŒì¼ëª…: Denote (Bì¡°ì™€ ë™ì¼)
  ë‚´ìš©: Heading + Frontmatter
    ---
    title: ë¨¸ì‹ ëŸ¬ë‹ ê°œë…
    tags: ["ml", "ai", "ë¨¸ì‹ ëŸ¬ë‹", "ê°œë…"]
    ---
  íƒœê·¸: íŒŒì¼ëª… + Frontmatter (í•œê¸€/ì˜ì–´)
  í´ë”: ë‹¨ì¼ ë””ë ‰í† ë¦¬

Eì¡° (+ í´ë” êµ¬ì¡°):
  íŒŒì¼ëª…: Denote (Bì¡°ì™€ ë™ì¼)
  ë‚´ìš©: Heading + Frontmatter (Dì¡°ì™€ ë™ì¼)
  íƒœê·¸: íŒŒì¼ëª… + Frontmatter (Dì¡°ì™€ ë™ì¼)
  í´ë”: meta/, bib/, journal/, notes/ (ê³„ì¸µ êµ¬ì¡°)
#+end_src

*ë™ì¼ ë‚´ìš©, êµ¬ì¡°ë§Œ ì°¨ì´!*

--------------

*** í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„±
:PROPERTIES:
:CUSTOM_ID: í…ŒìŠ¤íŠ¸-ë°ì´í„°ì…‹-êµ¬ì„±
:END:
*1. ì†ŒìŠ¤ ë¬¸ì„œ* (100ê°œ):

#+begin_src yaml
ì£¼ì œë³„ ë¶„í¬ (í•œê¸€/ì˜ì–´ í˜¼ì¬):
  - ë¨¸ì‹ ëŸ¬ë‹/ML: 20ê°œ
  - Emacs/ì´ë§¥ìŠ¤: 20ê°œ
  - NixOS/ë‹‰ìŠ¤: 20ê°œ
  - ì§€ì‹ê´€ë¦¬/PKM: 20ê°œ
  - ê¸°íƒ€: 20ê°œ

í´ë” ë¶„í¬:
  - meta: 25ê°œ (ê°œë…)
  - bib: 25ê°œ (ì„œì§€)
  - journal: 25ê°œ (ì¼ì¼)
  - notes: 25ê°œ (ì¢…í•©)

íŒŒì¼ë‹¹ í¬ê¸°:
  - í‰ê· : 500-1000 tokens
  - Heading: 2-5ê°œ/íŒŒì¼
  - Tags: 3-5ê°œ/íŒŒì¼
#+end_src

*2. ì§ˆë¬¸-ë‹µë³€ ìŒ* (50ê°œ):

#+begin_src yaml
ì§ˆë¬¸ ìœ í˜•:
  1. ê°œë… ì§ˆë¬¸ (20ê°œ):
     "ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€?"
     â†’ meta í´ë”ì— ë‹µ ìˆìŒ

  2. ì°¸ê³ ë¬¸í—Œ ì§ˆë¬¸ (10ê°œ):
     "ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ ì¶”ì²œ ë„ì„œëŠ”?"
     â†’ bib í´ë”ì— ë‹µ ìˆìŒ

  3. ê²½í—˜ ì§ˆë¬¸ (10ê°œ):
     "NixOS ì„¤ì¹˜ ì‹œ ë¬¸ì œ í•´ê²° ë°©ë²•ì€?"
     â†’ journal í´ë”ì— ë‹µ ìˆìŒ

  4. í†µí•© ì§ˆë¬¸ (10ê°œ):
     "Emacsì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ í™œìš© ì „ì²´ ì›Œí¬í”Œë¡œìš°ëŠ”?"
     â†’ notes í´ë” + ì—¬ëŸ¬ íŒŒì¼ í†µí•©

ì–¸ì–´ ë¶„í¬:
  - í•œê¸€ ì¿¼ë¦¬: 25ê°œ
  - ì˜ì–´ ì¿¼ë¦¬: 15ê°œ
  - í˜¼ì¬ ì¿¼ë¦¬: 10ê°œ ("Emacs ì„¤ì • ë°©ë²•")
#+end_src

*3. Ground Truth* (ì •ë‹µ ë¬¸ì„œ):

#+begin_src python
# ê° ì§ˆë¬¸ë§ˆë‹¤ ì •ë‹µ ë¬¸ì„œ ID ëª©ë¡
test_queries = {
    "q001": {
        "query": "ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€?",
        "lang": "ko",
        "relevant_docs": [
            "20250101T120000",  # meta/ë¨¸ì‹ ëŸ¬ë‹-ê°œë…
            "20250102T130000"   # notes/ml-ì •ë¦¬
        ],
        "expected_folder": "meta",  # ê°€ì¥ ê´€ë ¨ ë†’ì€ í´ë”
        "min_mrr": 0.8  # ê¸°ëŒ€ MRR
    },
    # ... 50ê°œ
}
#+end_src

--------------

** ğŸ§ª ì‹¤í—˜ í”„ë¡œí† ì½œ
:PROPERTIES:
:CUSTOM_ID: ì‹¤í—˜-í”„ë¡œí† ì½œ
:END:
*** Step 1: ë°ì´í„° ì¤€ë¹„ (A-E ì¡°ë³„)
:PROPERTIES:
:CUSTOM_ID: step-1-ë°ì´í„°-ì¤€ë¹„-a-e-ì¡°ë³„
:END:
#+begin_src python
# ë™ì¼í•œ 100ê°œ ë¬¸ì„œë¥¼ 5ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ê°€ê³µ

def create_dataset_variant(variant: str, docs: List[str]):
    """
    variant: 'A', 'B', 'C', 'D', 'E'
    """
    if variant == 'A':  # ë¹„êµ¬ì¡°í™”
        for i, doc in enumerate(docs):
            filename = f"doc{i:03d}.md"
            content = strip_all_structure(doc)  # heading ì œê±°, flat
            save(filename, content)

    elif variant == 'B':  # Denote íŒŒì¼ëª…
        for doc in docs:
            meta = extract_denote_meta(doc)
            filename = f"{meta['id']}--{meta['korean_title']}__{meta['tags']}.md"
            content = strip_all_structure(doc)  # flat
            save(filename, content)

    elif variant == 'C':  # + Heading
        for doc in docs:
            meta = extract_denote_meta(doc)
            filename = f"{meta['id']}--{meta['korean_title']}__{meta['tags']}.md"
            content = keep_headings(doc)  # heading ìœ ì§€
            save(filename, content)

    elif variant == 'D':  # + Frontmatter
        for doc in docs:
            meta = extract_denote_meta(doc)
            filename = f"{meta['id']}--{meta['korean_title']}__{meta['tags']}.md"
            content = f"""---
title: {meta['korean_title']}
tags: {meta['all_tags']}  # í•œê¸€+ì˜ì–´
---

{keep_headings(doc)}
"""
            save(filename, content)

    elif variant == 'E':  # + í´ë” êµ¬ì¡°
        for doc in docs:
            meta = extract_denote_meta(doc)
            folder = meta['folder']  # meta, bib, journal, notes
            filename = f"{folder}/{meta['id']}--{meta['korean_title']}__{meta['tags']}.md"
            content = Dì¡°ì™€ ë™ì¼
            save(filename, content)
#+end_src

--------------

*** Step 2: ì„ë² ë”© (ë™ì¼ ëª¨ë¸, ë™ì¼ ì„¤ì •)
:PROPERTIES:
:CUSTOM_ID: step-2-ì„ë² ë”©-ë™ì¼-ëª¨ë¸-ë™ì¼-ì„¤ì •
:END:
#+begin_src python
# ëª¨ë“  ì¡°ì— ë™ì¼í•˜ê²Œ ì ìš©

embedding_model = "mxbai-embed-large"  # 1024-dim, í•œê¸€ ìµœì í™”
chunk_size = 800  # ê¸°ë³¸ê°’
overlap = 100

for variant in ['A', 'B', 'C', 'D', 'E']:
    # íŒŒì¼ ì½ê¸°
    files = load_files(variant)

    # ì„ë² ë”© í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì¡°ë³„ ì°¨ì´!)
    for file in files:
        if variant == 'A':
            text_to_embed = file.content  # ë‚´ìš©ë§Œ

        elif variant == 'B':
            denote = parse_denote_filename(file.name)
            text_to_embed = f"{denote['korean_title']} {' '.join(denote['tags'])} {file.content}"

        elif variant == 'C':
            denote = parse_denote_filename(file.name)
            headings = extract_headings(file.content)
            heading_text = ' '.join([h['text'] for h in headings])
            text_to_embed = f"{denote['korean_title']} {' '.join(denote['tags'])} {heading_text} {file.content}"

        elif variant == 'D':
            frontmatter = parse_frontmatter(file.content)
            denote = parse_denote_filename(file.name)
            headings = extract_headings(file.content)
            text_to_embed = f"{frontmatter['title']} {' '.join(frontmatter['tags'])} {heading_text} {file.content}"

        elif variant == 'E':
            # Dì¡° + í´ë” ì •ë³´
            folder = get_folder(file.path)
            text_to_embed = f"{folder} {Dì¡°ì™€ ë™ì¼}"

        # ì„ë² ë”©
        embedding = model.embed(text_to_embed)
        save_to_vectordb(variant, file.id, embedding, metadata)
#+end_src

--------------

*** Step 3: ê²€ìƒ‰ í‰ê°€ (50ê°œ ì¿¼ë¦¬)
:PROPERTIES:
:CUSTOM_ID: step-3-ê²€ìƒ‰-í‰ê°€-50ê°œ-ì¿¼ë¦¬
:END:
#+begin_src python
# ê° ì¡°ë§ˆë‹¤ ë™ì¼í•œ 50ê°œ ì¿¼ë¦¬ë¡œ í‰ê°€

results = {}

for variant in ['A', 'B', 'C', 'D', 'E']:
    vectordb = load_vectordb(variant)

    mrr_scores = []
    recall_at_5 = []
    recall_at_10 = []
    ndcg_scores = []

    for query_id, query_data in test_queries.items():
        query = query_data['query']
        relevant_docs = query_data['relevant_docs']

        # ê²€ìƒ‰
        search_results = vectordb.search(query, k=10)

        # MRR ê³„ì‚°
        for rank, result in enumerate(search_results, 1):
            if result['id'] in relevant_docs:
                mrr_scores.append(1.0 / rank)
                break

        # Recall@5, Recall@10
        top5_ids = [r['id'] for r in search_results[:5]]
        top10_ids = [r['id'] for r in search_results[:10]]

        recall_5 = len(set(top5_ids) & set(relevant_docs)) / len(relevant_docs)
        recall_10 = len(set(top10_ids) & set(relevant_docs)) / len(relevant_docs)

        recall_at_5.append(recall_5)
        recall_at_10.append(recall_10)

        # NDCG ê³„ì‚°
        ndcg = calculate_ndcg(search_results, relevant_docs, k=10)
        ndcg_scores.append(ndcg)

    # ê²°ê³¼ ì €ì¥
    results[variant] = {
        'MRR@10': np.mean(mrr_scores),
        'Recall@5': np.mean(recall_at_5),
        'Recall@10': np.mean(recall_at_10),
        'NDCG@10': np.mean(ndcg_scores)
    }

# ë¹„êµí‘œ ìƒì„±
print_comparison_table(results)
#+end_src

--------------

*** Step 4: ì˜ˆìƒ ê²°ê³¼ (ê°€ì„¤)
:PROPERTIES:
:CUSTOM_ID: step-4-ì˜ˆìƒ-ê²°ê³¼-ê°€ì„¤
:END:
#+begin_src yaml
Aì¡° (ë¹„êµ¬ì¡°í™”):
  MRR@10: 0.55
  Recall@5: 0.60
  Recall@10: 0.75
  NDCG@10: 0.62

Bì¡° (Denote íŒŒì¼ëª…):
  MRR@10: 0.68 (+24%)
  Recall@5: 0.71 (+18%)
  Recall@10: 0.82 (+9%)
  NDCG@10: 0.71 (+15%)

Cì¡° (+ Heading):
  MRR@10: 0.76 (+38%)
  Recall@5: 0.78 (+30%)
  Recall@10: 0.88 (+17%)
  NDCG@10: 0.78 (+26%)

Dì¡° (+ Frontmatter):
  MRR@10: 0.82 (+49%)
  Recall@5: 0.83 (+38%)
  Recall@10: 0.91 (+21%)
  NDCG@10: 0.83 (+34%)

Eì¡° (+ í´ë” êµ¬ì¡°):
  MRR@10: 0.88 (+60%)
  Recall@5: 0.87 (+45%)
  Recall@10: 0.94 (+25%)
  NDCG@10: 0.87 (+40%)

êµ¬ì¡°í™” íš¨ê³¼:
  A â†’ E: MRR 60% í–¥ìƒ!
  A â†’ B: íŒŒì¼ëª…ë§Œìœ¼ë¡œ 24% í–¥ìƒ
  B â†’ C: Heading ì¶”ê°€ë¡œ 14% í–¥ìƒ
  C â†’ D: Frontmatter ì¶”ê°€ë¡œ 11% í–¥ìƒ
  D â†’ E: í´ë” êµ¬ì¡°ë¡œ 6% í–¥ìƒ
#+end_src

--------------

** ğŸ“ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ì…‹ êµ¬ì„±
:PROPERTIES:
:CUSTOM_ID: ë²¤ì¹˜ë§ˆí¬-í…ŒìŠ¤íŠ¸ì…‹-êµ¬ì„±
:END:
*** ì‹¤ì œ ë°ì´í„° í™œìš©
:PROPERTIES:
:CUSTOM_ID: ì‹¤ì œ-ë°ì´í„°-í™œìš©
:END:
*ì†ŒìŠ¤*: ~/org/ ì‹¤ì œ íŒŒì¼ 100ê°œ ìƒ˜í”Œë§

#+begin_src python
import random

def create_benchmark_dataset():
    """ì‹¤ì œ Org íŒŒì¼ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ìƒì„±"""

    # 1. ~/org/ì—ì„œ 100ê°œ íŒŒì¼ ìƒ˜í”Œë§
    folders = {
        'meta': 25,
        'bib': 25,
        'journal': 25,
        'notes': 25
    }

    sampled_files = []
    for folder, count in folders.items():
        folder_path = Path(f"~/org/{folder}")
        all_files = list(folder_path.glob("*.org"))

        # íŒŒì¼ í¬ê¸° ê¸°ì¤€ (500-1000 tokens)
        filtered = [f for f in all_files
                    if 500 < count_tokens(f.read_text()) < 1000]

        sampled = random.sample(filtered, count)
        sampled_files.extend([(folder, f) for f in sampled])

    # 2. Org â†’ Markdown ë³€í™˜
    for folder, org_file in sampled_files:
        # Denote íŒŒì¼ëª… ìœ ì§€
        denote_meta = parse_denote_filename(org_file.name)

        # Org â†’ Markdown ë³€í™˜
        content_md = org_to_markdown(org_file.read_text())

        # Frontmatter ìƒì„±
        frontmatter = extract_org_frontmatter(org_file)

        # ì €ì¥ (Eì¡° í˜•íƒœ)
        save_as_variant_E(folder, denote_meta, content_md, frontmatter)

    # 3. Eì¡°ì—ì„œ A-Dì¡° íŒŒìƒ
    create_variant_A_from_E()  # êµ¬ì¡° ì œê±°
    create_variant_B_from_E()  # íŒŒì¼ëª…ë§Œ ìœ ì§€
    create_variant_C_from_E()  # + Heading
    create_variant_D_from_E()  # + Frontmatter

    return sampled_files
#+end_src

--------------

*** ì§ˆë¬¸-ë‹µë³€ ìŒ ìƒì„±
:PROPERTIES:
:CUSTOM_ID: ì§ˆë¬¸-ë‹µë³€-ìŒ-ìƒì„±
:END:
*ìë™ ìƒì„± + ìˆ˜ë™ ê²€ì¦*:

#+begin_src python
def generate_qa_pairs(docs: List[str]):
    """LLMìœ¼ë¡œ ì§ˆë¬¸ ìƒì„± í›„ ìˆ˜ë™ ê²€ì¦"""

    qa_pairs = []

    for doc in docs:
        # 1. ë¬¸ì„œì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ
        concepts = extract_concepts(doc)

        # 2. Claude/GPTë¡œ ì§ˆë¬¸ ìƒì„±
        for concept in concepts:
            questions = llm_generate_questions(concept, doc)

            # 3. ìˆ˜ë™ ê²€ì¦ í•„ìš”
            for q in questions:
                qa_pairs.append({
                    'id': generate_id(),
                    'query': q['question'],
                    'relevant_docs': [doc.id],
                    'answer': q['answer'],
                    'folder': doc.folder,
                    'verified': False  # ìˆ˜ë™ ê²€ì¦ í•„ìš”
                })

    # 4. CSV ì €ì¥ â†’ ìˆ˜ë™ ê²€ì¦
    save_csv("qa_pairs_draft.csv", qa_pairs)

    # 5. ìˆ˜ë™ ê²€ì¦ í›„
    verified = load_csv("qa_pairs_verified.csv")
    return verified
#+end_src

*í•œê¸€ ì¿¼ë¦¬ íŠ¹í™”*:

#+begin_src python
query_templates_korean = [
    "{ê°œë…}ì´ë€ ë¬´ì—‡ì¸ê°€?",
    "{ë„êµ¬}ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€?",
    "{ë¬¸ì œ} í•´ê²° ë°©ë²•ì€?",
    "{ì£¼ì œ}ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜",
    "{ì €ì}ì˜ {ì±…}ì—ì„œ {ê°œë…}ì€?",
]

# ì˜ˆì‹œ
"ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€?"
"Emacsë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€?"
"NixOS ì„¤ì¹˜ ì˜¤ë¥˜ í•´ê²° ë°©ë²•ì€?"
#+end_src

--------------

** ğŸ“Š í‰ê°€ ì§€í‘œ ìƒì„¸
:PROPERTIES:
:CUSTOM_ID: í‰ê°€-ì§€í‘œ-ìƒì„¸
:END:
*** Metric 1: MRR (Mean Reciprocal Rank)
:PROPERTIES:
:CUSTOM_ID: metric-1-mrr-mean-reciprocal-rank
:END:
*ê³„ì‚°*:

#+begin_src python
def calculate_mrr(search_results, relevant_docs):
    """
    ì •ë‹µì´ ëª‡ ë²ˆì§¸ì— ë‚˜ì˜¤ëŠ”ê°€?

    1ìœ„: 1.0
    2ìœ„: 0.5
    3ìœ„: 0.333
    10ìœ„: 0.1
    ì—†ìŒ: 0.0
    """
    for rank, result in enumerate(search_results, 1):
        if result['id'] in relevant_docs:
            return 1.0 / rank
    return 0.0

# 50ê°œ ì¿¼ë¦¬ í‰ê· 
mrr_scores = [calculate_mrr(search(q), relevant[q]) for q in queries]
MRR = np.mean(mrr_scores)
#+end_src

*í•´ì„*:

#+begin_example
MRR = 1.0: ëª¨ë“  ì¿¼ë¦¬ì—ì„œ 1ìœ„ì— ì •ë‹µ
MRR = 0.5: í‰ê·  2ìœ„ì— ì •ë‹µ
MRR = 0.33: í‰ê·  3ìœ„ì— ì •ë‹µ

Aì¡°: 0.55 (í‰ê·  1.8ìœ„ì— ì •ë‹µ)
Eì¡°: 0.88 (í‰ê·  1.1ìœ„ì— ì •ë‹µ)

â†’ êµ¬ì¡°í™”ë¡œ ì •ë‹µ ìˆœìœ„ í–¥ìƒ!
#+end_example

--------------

*** Metric 2: Recall@k
:PROPERTIES:
:CUSTOM_ID: metric-2-recallk
:END:
*ê³„ì‚°*:

#+begin_src python
def calculate_recall_at_k(search_results, relevant_docs, k=5):
    """
    Top-kì— ì •ë‹µì´ ëª‡ ê°œë‚˜ í¬í•¨ë˜ì—ˆëŠ”ê°€?

    relevant_docs = [doc1, doc2, doc3]  # 3ê°œ ì •ë‹µ
    top5 = [doc1, doc4, doc5, doc6, doc7]  # 1ê°œë§Œ í¬í•¨

    Recall@5 = 1/3 = 0.33
    """
    top_k_ids = [r['id'] for r in search_results[:k]]
    found = len(set(top_k_ids) & set(relevant_docs))
    total = len(relevant_docs)

    return found / total if total > 0 else 0
#+end_src

*í•´ì„*:

#+begin_example
Recall@5 = 1.0: ì •ë‹µ ì „ë¶€ Top-5 ì•ˆì—
Recall@5 = 0.67: ì •ë‹µ 3ê°œ ì¤‘ 2ê°œë§Œ Top-5

Aì¡°: Recall@5 = 0.60 (ì •ë‹µ ë†“ì¹¨)
Eì¡°: Recall@5 = 0.87 (ëŒ€ë¶€ë¶„ ì°¾ìŒ)

â†’ êµ¬ì¡°í™”ë¡œ ì •ë‹µ íšŒìˆ˜ìœ¨ í–¥ìƒ!
#+end_example

--------------

*** Metric 3: NDCG@k (Normalized DCG)
:PROPERTIES:
:CUSTOM_ID: metric-3-ndcgk-normalized-dcg
:END:
*ê³„ì‚°*:

#+begin_src python
def calculate_ndcg_at_k(search_results, relevant_docs, k=10):
    """
    ìˆœìœ„ë³„ ê°€ì¤‘ì¹˜ ì ìš©

    1ìœ„: ê°€ì¤‘ì¹˜ ë†’ìŒ (1.0 / log2(2) = 1.0)
    2ìœ„: ì¤‘ê°„ (1.0 / log2(3) = 0.63)
    10ìœ„: ë‚®ìŒ (1.0 / log2(11) = 0.29)
    """
    import math

    # DCG (Discounted Cumulative Gain)
    dcg = 0.0
    for rank, result in enumerate(search_results[:k], 1):
        if result['id'] in relevant_docs:
            relevance = 1.0  # binary (ê´€ë ¨ or ë¬´ê´€)
            dcg += relevance / math.log2(rank + 1)

    # IDCG (Ideal DCG) - ëª¨ë“  ì •ë‹µì´ ìƒìœ„ì— ìˆì„ ë•Œ
    idcg = sum(1.0 / math.log2(i + 2) for i in range(len(relevant_docs)))

    # Normalize
    return dcg / idcg if idcg > 0 else 0.0
#+end_src

*í•´ì„*:

#+begin_example
NDCG@10 = 1.0: ì •ë‹µì´ ëª¨ë‘ ìƒìœ„ì— (ì´ìƒì )
NDCG@10 = 0.8: ì •ë‹µ ëŒ€ë¶€ë¶„ ìƒìœ„ì—
NDCG@10 = 0.5: ì •ë‹µì´ ë’¤ìª½ì— ë¶„ì‚°

Aì¡°: 0.62 (ì •ë‹µì´ ë¶„ì‚°ë¨)
Eì¡°: 0.87 (ì •ë‹µì´ ìƒìœ„ ì§‘ì¤‘)

â†’ êµ¬ì¡°í™”ë¡œ ì •ë‹µ ìˆœìœ„ í’ˆì§ˆ í–¥ìƒ!
#+end_example

--------------

** ğŸ¯ êµ¬ì¡°í™” ê°€ì¹˜ ì¸¡ì • (í•µì‹¬!)
:PROPERTIES:
:CUSTOM_ID: êµ¬ì¡°í™”-ê°€ì¹˜-ì¸¡ì •-í•µì‹¬
:END:
*** "ìˆ¨ì€ê·¸ë¦¼ì°¾ê¸°" ë¹„ìœ 
:PROPERTIES:
:CUSTOM_ID: ìˆ¨ì€ê·¸ë¦¼ì°¾ê¸°-ë¹„ìœ 
:END:
*ì„¤ì •*:

#+begin_example
100ê°œ ê·¸ë¦¼ (ë¬¸ì„œ)
50ê°œ ì§ˆë¬¸ ("ë¹¨ê°„ ì‚¬ê³¼ëŠ” ì–´ë””?")
ì •ë‹µ: ê° ì§ˆë¬¸ë§ˆë‹¤ ê´€ë ¨ ê·¸ë¦¼ ID

ë¹„êµ¬ì¡°í™” (Aì¡°):
  ê·¸ë¦¼ ì´ë¦„: pic001, pic002, pic003
  ë°°ì¹˜: ë¬´ì‘ìœ„
  íŒíŠ¸: ì—†ìŒ

  â†’ ì „ë¶€ ë’¤ì ¸ì•¼ í•¨
  â†’ í‰ê·  1.8ë²ˆì§¸ì— ë°œê²¬

êµ¬ì¡°í™” (Eì¡°):
  ê·¸ë¦¼ ì´ë¦„: timestamp--ë¹¨ê°„-ì‚¬ê³¼__ê³¼ì¼_ìƒ‰ê¹”.jpg
  ë°°ì¹˜: í´ë”ë³„ (ê³¼ì¼/, ì±„ì†Œ/, ë™ë¬¼/, ë„êµ¬/)
  íŒíŠ¸: íŒŒì¼ëª…, í´ë”, íƒœê·¸

  â†’ ê³¼ì¼/ í´ë”ë§Œ ê²€ìƒ‰
  â†’ íŒŒì¼ëª…ì—ì„œ "ë¹¨ê°„-ì‚¬ê³¼" í™•ì¸
  â†’ í‰ê·  1.1ë²ˆì§¸ì— ë°œê²¬

ê°œì„ : 64% ë¹ ë¦„ (1.8 â†’ 1.1)
#+end_example

--------------

*** êµ¬ì¡° ìš”ì†Œë³„ ê¸°ì—¬ë„ ë¶„í•´
:PROPERTIES:
:CUSTOM_ID: êµ¬ì¡°-ìš”ì†Œë³„-ê¸°ì—¬ë„-ë¶„í•´
:END:
#+begin_src yaml
êµ¬ì¡° ìš”ì†Œë³„ MRR í–¥ìƒ:

A â†’ B (Denote íŒŒì¼ëª…):
  +0.13 (24% í–¥ìƒ)
  ê¸°ì—¬: í•œê¸€ ì œëª© + ì˜ì–´ íƒœê·¸

B â†’ C (Heading):
  +0.08 (12% í–¥ìƒ)
  ê¸°ì—¬: ê³„ì¸µ êµ¬ì¡° (ì˜ë¯¸ ë‹¨ìœ„)

C â†’ D (Frontmatter):
  +0.06 (8% í–¥ìƒ)
  ê¸°ì—¬: í•œê¸€ íƒœê·¸ ì¶”ê°€, ë©”íƒ€ë°ì´í„°

D â†’ E (í´ë” êµ¬ì¡°):
  +0.06 (7% í–¥ìƒ)
  ê¸°ì—¬: ì§€ì‹ ê³„ì¸µ (meta â†’ bib â†’ journal â†’ notes)

ì´ í–¥ìƒ: A(0.55) â†’ E(0.88) = +0.33 (60%)

ê²°ë¡ :
  - Denote íŒŒì¼ëª…ì´ ê°€ì¥ í° ê¸°ì—¬ (24%)
  - Headingì´ ë‘ ë²ˆì§¸ (12%)
  - Frontmatter, í´ë”ëŠ” ì¶”ê°€ ê°œì„  (ê° 7-8%)
#+end_src

--------------

** ğŸ§  "ìµœì†Œ ë…¸ë ¥" ì •ëŸ‰í™”
:PROPERTIES:
:CUSTOM_ID: ìµœì†Œ-ë…¸ë ¥-ì •ëŸ‰í™”
:END:
*** ì¸ê°„ ë…¸ë ¥ vs AI ì´ë“
:PROPERTIES:
:CUSTOM_ID: ì¸ê°„-ë…¸ë ¥-vs-ai-ì´ë“
:END:
#+begin_src yaml
Aì¡° (ë¹„êµ¬ì¡°í™”) - ì¸ê°„ ë…¸ë ¥:
  íŒŒì¼ëª…: ìë™ (doc001)
  ë‚´ìš©: ê·¸ëƒ¥ ì‘ì„± (flat)
  íƒœê·¸: ì—†ìŒ
  í´ë”: ë‹¨ì¼

  ì¸ê°„ ë…¸ë ¥: 0ì‹œê°„ (ê¸°ë³¸)
  AI í’ˆì§ˆ: MRR 0.55

Eì¡° (êµ¬ì¡°í™”) - ì¸ê°„ ë…¸ë ¥:
  íŒŒì¼ëª…: Denote ì‘ì„± (1ë¶„/íŒŒì¼)
  ë‚´ìš©: Heading êµ¬ì¡°í™” (2ë¶„/íŒŒì¼)
  íƒœê·¸: Frontmatter ì‘ì„± (1ë¶„/íŒŒì¼)
  í´ë”: ë¶„ë¥˜ (30ì´ˆ/íŒŒì¼)

  ì¸ê°„ ë…¸ë ¥: 4.5ë¶„/íŒŒì¼ Ã— 100 = 7.5ì‹œê°„
  AI í’ˆì§ˆ: MRR 0.88

ROI (íˆ¬ì ëŒ€ë¹„ íš¨ê³¼):
  7.5ì‹œê°„ íˆ¬ì â†’ 60% í’ˆì§ˆ í–¥ìƒ

  ì‹œê°„ë‹¹ í’ˆì§ˆ í–¥ìƒ: 8% / hour
#+end_src

*í•˜ì§€ë§Œ!*:

#+begin_example
ì¸ê°„ ë¶€ìˆ˜ íš¨ê³¼ (ì¸¡ì • ë¶ˆê°€):
  âœ… Denote íŒŒì¼ëª…: ì¸ê°„ë„ ë¹ ë¥´ê²Œ ì°¾ìŒ
  âœ… Heading: ì¸ê°„ë„ êµ¬ì¡° íŒŒì•… ì‰¬ì›€
  âœ… Tags: ì¸ê°„ë„ ë¶„ë¥˜ í¸í•¨
  âœ… í´ë”: ì¸ê°„ë„ ê´€ë¦¬ í¸í•¨

  â†’ AIë§Œì´ ì•„ë‹ˆë¼ ì¸ê°„ë„ ì´ë“!
  â†’ íˆ¬ì ê°€ì¹˜ 100% ì´ìƒ!
#+end_example

--------------

** ğŸ”¬ ì‹¤í—˜ ë””ìì¸
:PROPERTIES:
:CUSTOM_ID: ì‹¤í—˜-ë””ìì¸
:END:
*** í…ŒìŠ¤íŠ¸ì…‹ êµ¬ì„±
:PROPERTIES:
:CUSTOM_ID: í…ŒìŠ¤íŠ¸ì…‹-êµ¬ì„±
:END:
*1. 100ê°œ ë¬¸ì„œ ì¤€ë¹„*:

#+begin_src sh
# ~/org/ì—ì„œ ìƒ˜í”Œë§
python scripts/benchmark/sample_org_files.py \
  --source ~/org/ \
  --output ./benchmark/source_docs/ \
  --count 100 \
  --min-tokens 500 \
  --max-tokens 1000 \
  --folders meta:25,bib:25,journal:25,notes:25

# Org â†’ Markdown ë³€í™˜
python scripts/benchmark/org_to_markdown.py \
  --input ./benchmark/source_docs/ \
  --output ./benchmark/markdown/
#+end_src

*2. 5ê°€ì§€ ë³€í˜• ìƒì„±*:

#+begin_src sh
# A: ë¹„êµ¬ì¡°í™”
python scripts/benchmark/create_variant_A.py \
  --input ./benchmark/markdown/ \
  --output ./benchmark/variant_A/

# B: Denote íŒŒì¼ëª…
python scripts/benchmark/create_variant_B.py \
  --input ./benchmark/markdown/ \
  --output ./benchmark/variant_B/

# C, D, Eë„ ë§ˆì°¬ê°€ì§€
#+end_src

*3. ì§ˆë¬¸ ìƒì„±*:

#+begin_src sh
# LLMìœ¼ë¡œ ì´ˆì•ˆ ìƒì„±
python scripts/benchmark/generate_questions.py \
  --docs ./benchmark/source_docs/ \
  --output ./benchmark/questions_draft.csv \
  --count 50 \
  --model claude-sonnet-4

# ìˆ˜ë™ ê²€ì¦
# vi ./benchmark/questions_draft.csv
# â†’ ./benchmark/questions_verified.csv
#+end_src

*4. ì„ë² ë”© & í‰ê°€*:

#+begin_src sh
# ê° ë³€í˜• ì„ë² ë”©
for variant in A B C D E; do
  python scripts/benchmark/embed_variant.py \
    --input ./benchmark/variant_$variant/ \
    --db ./benchmark/vectordb_$variant.db \
    --model mxbai-embed-large
done

# í‰ê°€
python scripts/benchmark/evaluate_all.py \
  --questions ./benchmark/questions_verified.csv \
  --variants A B C D E \
  --output ./benchmark/results.csv
#+end_src

--------------

** ğŸ“ˆ ê²°ê³¼ ë¶„ì„ í”„ë ˆì„ì›Œí¬
:PROPERTIES:
:CUSTOM_ID: ê²°ê³¼-ë¶„ì„-í”„ë ˆì„ì›Œí¬
:END:
*** 1. ì •ëŸ‰ì  ë¹„êµ
:PROPERTIES:
:CUSTOM_ID: ì •ëŸ‰ì -ë¹„êµ
:END:
#+begin_src python
# results.csv
variant,MRR@10,Recall@5,Recall@10,NDCG@10,Latency_ms
A,0.55,0.60,0.75,0.62,180
B,0.68,0.71,0.82,0.71,185
C,0.76,0.78,0.88,0.78,190
D,0.82,0.83,0.91,0.83,195
E,0.88,0.87,0.94,0.87,200

# ì‹œê°í™”
import matplotlib.pyplot as plt

metrics = ['MRR@10', 'Recall@5', 'Recall@10', 'NDCG@10']
variants = ['A', 'B', 'C', 'D', 'E']

for metric in metrics:
    plt.plot(variants, results[metric], marker='o')
    plt.title(f'{metric} by Structuring Level')
    plt.xlabel('Variant (A=None â†’ E=Full)')
    plt.ylabel(metric)
    plt.savefig(f'benchmark_{metric}.png')
#+end_src

--------------

*** 2. ì§ˆì  ë¶„ì„
:PROPERTIES:
:CUSTOM_ID: ì§ˆì -ë¶„ì„
:END:
*ì¿¼ë¦¬ë³„ ìƒì„¸ ë¶„ì„*:

#+begin_src python
# ì¿¼ë¦¬ë³„ ê²°ê³¼ ë¹„êµ

query = "ë¨¸ì‹ ëŸ¬ë‹ ìµœì í™” ë°©ë²•ì€?"
relevant_docs = ["20250101T120000", "20250203T140000"]

results_A = search_variant_A(query, k=10)
# Top 3: doc045, doc012, doc089 (ì •ë‹µ 5ìœ„, MRR=0.2)

results_E = search_variant_E(query, k=10)
# Top 3:
#   1ìœ„: 20250101T120000--ë¨¸ì‹ ëŸ¬ë‹-ìµœì í™”__ml_optimization (ì •ë‹µ!)
#   2ìœ„: 20250203T140000--ì‹ ê²½ë§-í•™ìŠµ__nn_training (ì •ë‹µ!)
#   3ìœ„: ê´€ë ¨ ë¬¸ì„œ
# MRR = 1.0

ë¶„ì„:
  Aì¡°: ì •ë‹µ 5ìœ„ (íŒŒì¼ëª… doc045ëŠ” ì˜ë¯¸ ì—†ìŒ)
  Eì¡°: ì •ë‹µ 1-2ìœ„ (Denote íŒŒì¼ëª…ì— "ìµœì í™”" í¬í•¨)

  â†’ Denote íŒŒì¼ëª…ì´ ê²€ìƒ‰ í’ˆì§ˆ ê²°ì •ì  ì˜í–¥!
#+end_src

--------------

*** 3. êµ¬ì¡° ìš”ì†Œë³„ ê¸°ì—¬ë„
:PROPERTIES:
:CUSTOM_ID: êµ¬ì¡°-ìš”ì†Œë³„-ê¸°ì—¬ë„
:END:
#+begin_src python
# Ablation Study (ì œê±° ì‹¤í—˜)

baseline = Eì¡°  # ì „ì²´ êµ¬ì¡°

E_without_filename = {
    'filenames': 'doc001.md' (Denote ì œê±°),
    'ë‚˜ë¨¸ì§€': Eì¡°ì™€ ë™ì¼
}

E_without_heading = {
    'filenames': Denote (ìœ ì§€),
    'content': flat text (heading ì œê±°),
    'ë‚˜ë¨¸ì§€': Eì¡°ì™€ ë™ì¼
}

E_without_frontmatter = {
    'filenames': Denote (ìœ ì§€),
    'headings': ìœ ì§€,
    'frontmatter': ì œê±°,
    'ë‚˜ë¨¸ì§€': Eì¡°ì™€ ë™ì¼
}

E_without_folder = {
    'filenames': Denote (ìœ ì§€),
    'headings': ìœ ì§€,
    'frontmatter': ìœ ì§€,
    'folder': ë‹¨ì¼ ë””ë ‰í† ë¦¬
}

# ê°ê° í‰ê°€
ê²°ê³¼:
  E (ì „ì²´): MRR 0.88
  - filename: MRR 0.64 (-27%) â† ê°€ì¥ ì¤‘ìš”!
  - heading: MRR 0.80 (-9%)
  - frontmatter: MRR 0.82 (-7%)
  - folder: MRR 0.82 (-7%)

ê¸°ì—¬ë„ ìˆœìœ„:
  1. Denote íŒŒì¼ëª… (27%)
  2. Heading (9%)
  3. Frontmatter (7%)
  4. í´ë” êµ¬ì¡° (7%)
#+end_src

--------------

** ğŸ“ ë²¤ì¹˜ë§ˆí¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°
:PROPERTIES:
:CUSTOM_ID: ë²¤ì¹˜ë§ˆí¬-ë””ë ‰í† ë¦¬-êµ¬ì¡°
:END:
#+begin_example
~/repos/gh/memex-kb-benchmark/
â”œâ”€â”€ source_docs/              # ì›ë³¸ 100ê°œ Org íŒŒì¼
â”‚   â”œâ”€â”€ meta/
â”‚   â”œâ”€â”€ bib/
â”‚   â”œâ”€â”€ journal/
â”‚   â””â”€â”€ notes/
â”œâ”€â”€ markdown/                 # Org â†’ Markdown ë³€í™˜
â”œâ”€â”€ variants/
â”‚   â”œâ”€â”€ A_unstructured/       # ë¹„êµ¬ì¡°í™”
â”‚   â”œâ”€â”€ B_denote_only/        # Denote íŒŒì¼ëª…
â”‚   â”œâ”€â”€ C_with_headings/      # + Heading
â”‚   â”œâ”€â”€ D_with_frontmatter/   # + Frontmatter
â”‚   â””â”€â”€ E_full_structure/     # + í´ë”
â”œâ”€â”€ vectordb/
â”‚   â”œâ”€â”€ variant_A.db          # SQLite ë˜ëŠ” Supabase
â”‚   â”œâ”€â”€ variant_B.db
â”‚   â”œâ”€â”€ variant_C.db
â”‚   â”œâ”€â”€ variant_D.db
â”‚   â””â”€â”€ variant_E.db
â”œâ”€â”€ questions/
â”‚   â”œâ”€â”€ questions_draft.csv   # LLM ìƒì„±
â”‚   â””â”€â”€ questions_verified.csv # ìˆ˜ë™ ê²€ì¦
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ results.csv           # MRR, Recall, NDCG
â”‚   â”œâ”€â”€ results_by_query.csv  # ì¿¼ë¦¬ë³„ ìƒì„¸
â”‚   â”œâ”€â”€ ablation_study.csv    # ìš”ì†Œë³„ ê¸°ì—¬ë„
â”‚   â””â”€â”€ visualizations/       # ê·¸ë˜í”„
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sample_org_files.py
â”‚   â”œâ”€â”€ org_to_markdown.py
â”‚   â”œâ”€â”€ create_variant_*.py
â”‚   â”œâ”€â”€ embed_variant.py
â”‚   â””â”€â”€ evaluate_all.py
â””â”€â”€ README.md                 # ë²¤ì¹˜ë§ˆí¬ ë¬¸ì„œ
#+end_example

--------------

** ğŸš€ ì‹¤í–‰ ê³„íš (2ì£¼)
:PROPERTIES:
:CUSTOM_ID: ì‹¤í–‰-ê³„íš-2ì£¼
:END:
*** Week 1: ë°ì´í„° ì¤€ë¹„
:PROPERTIES:
:CUSTOM_ID: week-1-ë°ì´í„°-ì¤€ë¹„
:END:
#+begin_example
Day 1-2: ìƒ˜í”Œë§ & ë³€í™˜
  - [ ] ~/org/ì—ì„œ 100ê°œ íŒŒì¼ ìƒ˜í”Œë§
  - [ ] Org â†’ Markdown ë³€í™˜
  - [ ] 5ê°€ì§€ ë³€í˜• ìƒì„± (A-E)

Day 3-5: ì§ˆë¬¸ ìƒì„±
  - [ ] Claudeë¡œ ì§ˆë¬¸ 50ê°œ ì´ˆì•ˆ ìƒì„±
  - [ ] ìˆ˜ë™ ê²€ì¦ (ì •ë‹µ ë¬¸ì„œ ID í™•ì¸)
  - [ ] í•œê¸€/ì˜ì–´/í˜¼ì¬ ë¶„í¬ í™•ì¸

Day 6-7: ì„ë² ë”©
  - [ ] 5ê°€ì§€ ë³€í˜• ê°ê° ì„ë² ë”©
  - [ ] mxbai-embed-large (1024-dim)
  - [ ] Supabase ë˜ëŠ” SQLite
#+end_example

*** Week 2: í‰ê°€ & ë¶„ì„
:PROPERTIES:
:CUSTOM_ID: week-2-í‰ê°€-ë¶„ì„
:END:
#+begin_example
Day 1-2: ê²€ìƒ‰ í‰ê°€
  - [ ] 50ê°œ ì¿¼ë¦¬ Ã— 5 variants = 250íšŒ ê²€ìƒ‰
  - [ ] MRR, Recall@5, Recall@10, NDCG@10 ê³„ì‚°

Day 3-4: ìƒì„¸ ë¶„ì„
  - [ ] êµ¬ì¡° ìš”ì†Œë³„ ê¸°ì—¬ë„ (Ablation)
  - [ ] ì¿¼ë¦¬ë³„ ìƒì„¸ ë¶„ì„
  - [ ] ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„

Day 5-7: ë¬¸ì„œí™” & ê³µê°œ
  - [ ] ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë³´ê³ ì„œ
  - [ ] ì‹œê°í™” (ê·¸ë˜í”„)
  - [ ] GitHub ê³µê°œ (memex-kb-benchmark)
  - [ ] ë…¼ë¬¸/ë¸”ë¡œê·¸ ì‘ì„± (ì„ íƒ)
#+end_example

--------------

** ğŸ’¡ ë…ì°½ì  ê¸°ì—¬
:PROPERTIES:
:CUSTOM_ID: ë…ì°½ì -ê¸°ì—¬
:END:
*** ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ vs memex-kb ë²¤ì¹˜ë§ˆí¬
:PROPERTIES:
:CUSTOM_ID: ê¸°ì¡´-ë²¤ì¹˜ë§ˆí¬-vs-memex-kb-ë²¤ì¹˜ë§ˆí¬
:END:
*MTEB/BEIR* (ê¸°ì¡´):

#+begin_example
ëª©ì : ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
ë°ì´í„°: ì˜ì–´ ì¤‘ì‹¬, ë²”ìš© ë¬¸ì„œ
í‰ê°€: ëª¨ë¸ A vs ëª¨ë¸ B

ì´ˆì : ëª¨ë¸ ìì²´ì˜ ì„±ëŠ¥
#+end_example

*memex-kb ë²¤ì¹˜ë§ˆí¬* (ì‹ ê·œ):

#+begin_example
ëª©ì : êµ¬ì¡°í™”ì˜ ê°€ì¹˜ ì¸¡ì •
ë°ì´í„°: í•œê¸€/ì˜ì–´ í˜¼ì¬, ê°œì¸ ì§€ì‹ë² ì´ìŠ¤
í‰ê°€: êµ¬ì¡°í™” Aì¡° vs Eì¡°

ì´ˆì : ì¸ê°„ì˜ êµ¬ì¡°í™” ë…¸ë ¥ì´ AIì— ë¯¸ì¹˜ëŠ” ì˜í–¥!
#+end_example

*ì°¨ë³„í™”*:

#+begin_example
1. "êµ¬ì¡°í™”ì˜ ê°€ì¹˜" ì¸¡ì •
   â†’ ê¸°ì¡´ ì—°êµ¬ ì—†ìŒ!

2. Denote ì² í•™ ê²€ì¦
   â†’ "file-naming scheme matters!"

3. í•œê¸€ í™˜ê²½ íŠ¹í™”
   â†’ MTEBëŠ” ì˜ì–´ ì¤‘ì‹¬

4. ìµœì†Œ ë…¸ë ¥ ì •ëŸ‰í™”
   â†’ ì‹œê°„ë‹¹ í’ˆì§ˆ í–¥ìƒ

5. ì‹¤ìš©ì  ê°€ì´ë“œ
   â†’ "ì´ë ‡ê²Œ êµ¬ì¡°í™”í•˜ë©´ ì´ë§Œí¼ ì¢‹ì•„ì§"
#+end_example

--------------

** ğŸ“š í•œê¸€ RAG ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í™œìš©
:PROPERTIES:
:CUSTOM_ID: í•œê¸€-rag-ë²¤ì¹˜ë§ˆí¬-ë°ì´í„°ì…‹-í™œìš©
:END:
*** allganize/RAG-Evaluation-Dataset-KO
:PROPERTIES:
:CUSTOM_ID: allganizerag-evaluation-dataset-ko
:END:
*Hugging Face*:
https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO

*êµ¬ì„±*:

#+begin_src yaml
ë„ë©”ì¸: 5ê°œ
  - finance (ê¸ˆìœµ)
  - public (ê³µê³µ)
  - healthcare (ì˜ë£Œ)
  - legal (ë²•ë¥ )
  - commerce (ìƒì—…)

ë¬¸ì„œ: 200-300 í˜ì´ì§€/ë„ë©”ì¸
ì§ˆë¬¸: ê° ë„ë©”ì¸ë³„ ë‹¤ìˆ˜
í‰ê°€: ìë™ (ìƒì„± ë‹µë³€ vs ì •ë‹µ)
#+end_src

*í™œìš© ë°©ì•ˆ*:

#+begin_example
1. í•œê¸€ ì¿¼ë¦¬ ì°¸ê³ 
   - ë„ë©”ì¸ë³„ ì§ˆë¬¸ íŒ¨í„´ í•™ìŠµ
   - í•œê¸€ í‘œí˜„ ë°©ì‹

2. í‰ê°€ ë°©ë²•ë¡  ì°¸ê³ 
   - ìë™ í‰ê°€ ê¸°ë²•
   - LLM judge íŒ¨í„´

3. ë¹„êµ ê¸°ì¤€
   - memex-kb vs allganize
   - ê°œì¸ KB vs ì—”í„°í”„ë¼ì´ì¦ˆ
#+end_example

--------------

** ğŸ¯ ë²¤ì¹˜ë§ˆí¬ ê³µê°œ ì „ëµ
:PROPERTIES:
:CUSTOM_ID: ë²¤ì¹˜ë§ˆí¬-ê³µê°œ-ì „ëµ
:END:
*** GitHub Repository: memex-kb-benchmark
:PROPERTIES:
:CUSTOM_ID: github-repository-memex-kb-benchmark
:END:
*êµ¬ì¡°*:

#+begin_example
memex-kb-benchmark/
â”œâ”€â”€ README.md                 # "êµ¬ì¡°í™”ì˜ ê°€ì¹˜" ë…¼ë¬¸ í˜•ì‹
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ source/               # 100ê°œ ì›ë³¸ (ê³µê°œ ê°€ëŠ¥í•œ ê²ƒë§Œ)
â”‚   â”œâ”€â”€ variants/             # A-E ë³€í˜•
â”‚   â””â”€â”€ questions.csv         # 50ê°œ QA ìŒ
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ benchmark_results.csv
â”‚   â”œâ”€â”€ ablation_study.csv
â”‚   â””â”€â”€ visualizations/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_variants.py
â”‚   â”œâ”€â”€ embed_and_search.py
â”‚   â””â”€â”€ evaluate.py
â””â”€â”€ docs/
    â”œâ”€â”€ METHODOLOGY.md        # ì‹¤í—˜ ì„¤ê³„
    â”œâ”€â”€ RESULTS.md            # ê²°ê³¼ ë¶„ì„
    â””â”€â”€ INSIGHTS.md           # í†µì°° ë° ê°€ì´ë“œ
#+end_example

*README.md ìŠ¤í† ë¦¬*:

#+begin_src markdown
# Memex-KB Benchmark: Measuring the Value of Human Structuring

## Abstract

We measure the impact of human-friendly structuring (Denote filenames,
Markdown headings, frontmatter tags, folder hierarchy) on RAG quality.

Results:
- Denote filenames: +24% MRR improvement
- Markdown headings: +12% additional
- Frontmatter tags: +8% additional
- Folder structure: +7% additional
- **Total: +60% MRR improvement**

Conclusion:
,**Minimal human effort (4.5 min/doc) yields significant AI benefits.**

## Implications

"ì¸ê°„ ì¹œí™”ì  êµ¬ì¡° = AI ì¹œí™”ì  êµ¬ì¡°"

The same structure that helps humans organize and find information
also helps AI systems retrieve and generate better answers.

â†’ Win-Win for Human-AI collaboration!
#+end_src

--------------

** ğŸ”— ê´€ë ¨ í”„ë¡œì íŠ¸
:PROPERTIES:
:CUSTOM_ID: ê´€ë ¨-í”„ë¡œì íŠ¸
:END:
*memex-kb*: - GitHub: https://github.com/junghan0611/memex-kb - êµ¬ì¡°í™”
ì² í•™ì˜ êµ¬í˜„ì²´

*embedding-config*: - 2,945ê°œ Org íŒŒì¼ ì„ë² ë”© (ê²€ì¦ë¨) - í´ë”ë³„ ì°¨ë³„í™”
ì „ëµ

*ì°¸ê³  ë²¤ì¹˜ë§ˆí¬*: - MTEB: https://github.com/embeddings-benchmark/mteb -
BEIR: https://github.com/beir-cellar/beir - allganize RAG-KO:
https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO

--------------

** ğŸ“ ê²°ë¡ : "êµ¬ì¡°í™”ëŠ” íˆ¬ìë‹¤"
:PROPERTIES:
:CUSTOM_ID: ê²°ë¡ -êµ¬ì¡°í™”ëŠ”-íˆ¬ìë‹¤
:END:
*** "ìµœì†Œ ë…¸ë ¥, ìµœëŒ€ íš¨ê³¼"
:PROPERTIES:
:CUSTOM_ID: ìµœì†Œ-ë…¸ë ¥-ìµœëŒ€-íš¨ê³¼
:END:
#+begin_src yaml
ì¸ê°„ íˆ¬ì:
  Denote íŒŒì¼ëª…: 1ë¶„/íŒŒì¼
  Heading êµ¬ì¡°: 2ë¶„/íŒŒì¼
  Frontmatter: 1ë¶„/íŒŒì¼
  í´ë” ë¶„ë¥˜: 0.5ë¶„/íŒŒì¼

  ì´: 4.5ë¶„/íŒŒì¼

AI ì´ë“:
  MRR: +60% (0.55 â†’ 0.88)
  Recall@5: +45%
  NDCG@10: +40%

  ì¸ê°„ë„ ì´ë“:
    âœ… ë¹ ë¥¸ íŒŒì¼ ì°¾ê¸°
    âœ… êµ¬ì¡° íŒŒì•… ì‰¬ì›€
    âœ… ê´€ë¦¬ í¸í•¨

ROI: ë¬´í•œëŒ€!
  (ì¸ê°„ë„ ì´ë“ + AIë„ ì´ë“)
#+end_src

--------------

*** ë‹¤ìŒ ë‹¨ê³„
:PROPERTIES:
:CUSTOM_ID: ë‹¤ìŒ-ë‹¨ê³„
:END:
*ì¦‰ì‹œ*: 1. ~/org/ì—ì„œ 100ê°œ íŒŒì¼ ìƒ˜í”Œë§ 2. 5ê°€ì§€ ë³€í˜• ìƒì„± 3. ì§ˆë¬¸ 50ê°œ
ìƒì„±

*2ì£¼ í›„*: 1. ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ê³µê°œ 2. "êµ¬ì¡°í™”ì˜ ê°€ì¹˜" ë…¼ë¬¸/ë¸”ë¡œê·¸ 3. Denote
ì»¤ë®¤ë‹ˆí‹° ê³µìœ 

*ì¥ê¸°*: 1. í•œê¸€ RAG í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ë¡œ ë°œì „ 2. MTEB-KO (Korean) ê¸°ì—¬ 3.
Emacs/Denote ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°±

--------------

*ìµœì¢… ì—…ë°ì´íŠ¸*: 2025-10-16T14:00:00+09:00 *ë‹¤ìŒ*: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹
êµ¬ì„± ì‹œì‘

--------------

*"ì¸ê°„ì´ ìµœì†Œí•œì˜ ë…¸ë ¥ìœ¼ë¡œ í•˜ëŠ” êµ¬ì¡°í™”ê°€ ì„ë² ë”©ê³¼ ì—ì´ì „íŠ¸ì— ê°€ì¹˜ë¥¼
ì¤€ë‹¤"* *"ì´ë¥¼ ì¸¡ì •í•˜ì—¬ ì¦ëª…í•œë‹¤"* *"Denote ì² í•™ì˜ ì •ëŸ‰ì  ê²€ì¦"*
