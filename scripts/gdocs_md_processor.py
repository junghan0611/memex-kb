#!/usr/bin/env python3
"""
Google Docs MD í›„ì²˜ë¦¬ê¸° (v3)

MCP get_doc_content ì¶œë ¥ ë˜ëŠ” Google Docs ë„¤ì´í‹°ë¸Œ MD ë‚´ë³´ë‚´ê¸°ë¥¼ ì²˜ë¦¬:
  1. íƒ­ë³„ MD íŒŒì¼ ë¶„í• 
  2. base64 ì¸ë¼ì¸ ì´ë¯¸ì§€ â†’ ë³„ë„ PNG íŒŒì¼ ì¶”ì¶œ
  3. íƒ­ë³„ ì´ë¯¸ì§€ ë§¤í•‘

Usage:
  # íƒ­ ë¶„í•  (MCP get_doc_content ê²°ê³¼)
  python gdocs_md_processor.py split-tabs --input mcp_output.json --output-dir ./output

  # ì´ë¯¸ì§€ ì¶”ì¶œ (Google Docs ë„¤ì´í‹°ë¸Œ MD ë‚´ë³´ë‚´ê¸°)
  python gdocs_md_processor.py extract-images --input exported.md --output-dir ./output

  # ì „ì²´ ì²˜ë¦¬ (íƒ­ ë¶„í•  + ì´ë¯¸ì§€ ì¶”ì¶œ)
  python gdocs_md_processor.py full --mcp-input mcp_output.json --md-input exported.md --output-dir ./output
"""

import argparse
import base64
import json
import logging
import os
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


@dataclass
class Tab:
    """Google Docs íƒ­ ì •ë³´"""
    name: str
    tab_id: Optional[str]
    depth: int  # ë“¤ì—¬ì“°ê¸° ê¹Šì´ (0=ìµœìƒìœ„)
    content: str
    line_start: int
    line_end: int

    @property
    def safe_filename(self) -> str:
        """íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¦„ ìƒì„±"""
        name = self.name.strip()
        # ìˆ«ì ì ‘ë‘ì‚¬ê°€ ìˆìœ¼ë©´ ìœ ì§€ (ì˜ˆ: "1. ì—°êµ¬ê°œë°œê³¼ì œì˜ ë°°ê²½")
        name = re.sub(r'[^\wê°€-í£\s\-\.]', '', name)
        name = re.sub(r'\s+', '-', name.strip())
        return name or "untitled"


@dataclass
class ExtractedImage:
    """ì¶”ì¶œëœ ì´ë¯¸ì§€ ì •ë³´"""
    ref_name: str       # image1, image2, ...
    format: str         # png, jpeg
    data: bytes
    filename: str       # output filename


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tab Splitter: MCP get_doc_content ê²°ê³¼ ë¶„í• 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TAB_MARKER_PATTERN = re.compile(
    r'^--- TAB:\s*(?P<indent>\s*)(?P<name>.+?)'
    r'(?:\s*\(\s*ID:\s*(?P<tab_id>[^)]+)\s*\))?'
    r'\s*---$'
)


def parse_mcp_content(input_path: str) -> str:
    """MCP ì¶œë ¥ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (JSON ë˜ëŠ” plain text)"""
    with open(input_path, 'r', encoding='utf-8') as f:
        raw = f.read()

    # JSON í˜•ì‹ì¸ ê²½ìš°
    try:
        data = json.loads(raw)
        if isinstance(data, dict) and 'result' in data:
            return data['result']
        return str(data)
    except (json.JSONDecodeError, ValueError):
        return raw


def split_tabs(content: str) -> List[Tab]:
    """MCP get_doc_content ê²°ê³¼ë¥¼ íƒ­ ë‹¨ìœ„ë¡œ ë¶„í• """
    lines = content.split('\n')
    tabs: List[Tab] = []
    current_tab: Optional[dict] = None

    for i, line in enumerate(lines, 1):
        match = TAB_MARKER_PATTERN.match(line)
        if match:
            # ì´ì „ íƒ­ ë§ˆë¬´ë¦¬
            if current_tab:
                current_tab['line_end'] = i - 1
                tab_lines = lines[current_tab['line_start'] - 1:current_tab['line_end']]
                current_tab['content'] = '\n'.join(tab_lines)
                tabs.append(Tab(**current_tab))

            indent = match.group('indent') or ''
            depth = len(indent) // 4  # 4ì¹¸ ë“¤ì—¬ì“°ê¸° = 1 depth
            current_tab = {
                'name': match.group('name').strip(),
                'tab_id': match.group('tab_id'),
                'depth': depth,
                'line_start': i + 1,  # ë§ˆì»¤ ë‹¤ìŒ ì¤„ë¶€í„°
                'line_end': len(lines),
                'content': '',
            }

    # ë§ˆì§€ë§‰ íƒ­
    if current_tab:
        current_tab['line_end'] = len(lines)
        tab_lines = lines[current_tab['line_start'] - 1:current_tab['line_end']]
        current_tab['content'] = '\n'.join(tab_lines)
        tabs.append(Tab(**current_tab))

    return tabs


def save_tabs(tabs: List[Tab], output_dir: str) -> List[str]:
    """íƒ­ë³„ MD íŒŒì¼ ì €ì¥"""
    out = Path(output_dir)
    out.mkdir(parents=True, exist_ok=True)

    saved_files = []
    for idx, tab in enumerate(tabs):
        # íƒ­ ì´ë¦„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„± (ë²ˆí˜¸ ì ‘ë‘ì‚¬ë¡œ ì •ë ¬ ë³´ì¥)
        filename = f"{idx:02d}--{tab.safe_filename}.md"
        filepath = out / filename

        # MD í—¤ë” ì¶”ê°€
        header = f"# {tab.name}\n\n"
        if tab.tab_id:
            header += f"<!-- tab-id: {tab.tab_id} -->\n\n"

        content = header + tab.content.strip() + '\n'

        filepath.write_text(content, encoding='utf-8')
        saved_files.append(str(filepath))
        logger.info(
            f"  [{idx:02d}] {tab.name} "
            f"(depth={tab.depth}, lines={tab.line_end - tab.line_start + 1})"
        )

    return saved_files


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Image Extractor: base64 ì´ë¯¸ì§€ â†’ PNG íŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# base64 ì´ë¯¸ì§€ ì •ì˜: [imageN]: <data:image/png;base64,...>
IMAGE_DEF_PATTERN = re.compile(
    r'^\[(?P<ref>image\d+)\]:\s*<data:image/(?P<fmt>png|jpeg|jpg);base64,'
    r'(?P<data>[A-Za-z0-9+/=\s]+)>$',
    re.MULTILINE,
)

# ì´ë¯¸ì§€ ì°¸ì¡°: ![][imageN]
IMAGE_REF_PATTERN = re.compile(r'!\[\]\[(?P<ref>image\d+)\]')


def extract_images(md_path: str, output_dir: str) -> str:
    """Google Docs ë„¤ì´í‹°ë¸Œ MDì—ì„œ base64 ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì°¸ì¡° ë³€í™˜

    Returns:
        ë³€í™˜ëœ MD ë‚´ìš© (base64 â†’ íŒŒì¼ ê²½ë¡œ)
    """
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    images_dir = Path(output_dir) / "images"
    images_dir.mkdir(parents=True, exist_ok=True)

    original_size = len(content)
    extracted: List[ExtractedImage] = []

    # base64 ì´ë¯¸ì§€ ì •ì˜ ì°¾ê¸° ë° ì¶”ì¶œ
    for match in IMAGE_DEF_PATTERN.finditer(content):
        ref_name = match.group('ref')
        fmt = match.group('fmt')
        raw_data = match.group('data').replace('\n', '').replace(' ', '')

        try:
            img_bytes = base64.b64decode(raw_data)
        except Exception as e:
            logger.warning(f"  {ref_name} base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            continue

        filename = f"{ref_name}.{fmt}"
        img_path = images_dir / filename
        img_path.write_bytes(img_bytes)

        extracted.append(ExtractedImage(
            ref_name=ref_name,
            format=fmt,
            data=img_bytes,
            filename=filename,
        ))
        logger.info(
            f"  {ref_name}.{fmt}: {len(img_bytes) / 1024:.1f} KB"
        )

    # base64 ì •ì˜ ì œê±°
    cleaned = IMAGE_DEF_PATTERN.sub('', content)

    # ì°¸ì¡°ë¥¼ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜: ![][imageN] â†’ ![imageN](images/imageN.png)
    def replace_ref(m):
        ref = m.group('ref')
        img = next((e for e in extracted if e.ref_name == ref), None)
        if img:
            return f"![{ref}](images/{img.filename})"
        return m.group(0)

    cleaned = IMAGE_REF_PATTERN.sub(replace_ref, cleaned)

    # í›„í–‰ ë¹ˆ ì¤„ ì •ë¦¬
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned).strip() + '\n'

    cleaned_size = len(cleaned)
    logger.info(
        f"  í¬ê¸°: {original_size / 1024:.0f}KB â†’ {cleaned_size / 1024:.0f}KB "
        f"({(1 - cleaned_size / original_size) * 100:.0f}% ê°ì†Œ)"
    )

    return cleaned


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_split_tabs(args):
    """íƒ­ ë¶„í•  ëª…ë ¹"""
    logger.info(f"MCP ì¶œë ¥ íŒŒì‹±: {args.input}")
    content = parse_mcp_content(args.input)
    tabs = split_tabs(content)
    logger.info(f"ë°œê²¬ëœ íƒ­: {len(tabs)}ê°œ")

    saved = save_tabs(tabs, args.output_dir)
    logger.info(f"ì €ì¥ ì™„ë£Œ: {len(saved)}ê°œ íŒŒì¼ â†’ {args.output_dir}")

    # ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“‚ íƒ­ ë¶„í•  ê²°ê³¼ ({len(tabs)}ê°œ íƒ­):")
    for idx, tab in enumerate(tabs):
        indent = "  " * tab.depth
        tid = f" ({tab.tab_id})" if tab.tab_id else ""
        print(f"  {indent}{idx:02d}. {tab.name}{tid}")


def cmd_extract_images(args):
    """ì´ë¯¸ì§€ ì¶”ì¶œ ëª…ë ¹"""
    logger.info(f"MD íŒŒì¼ ì²˜ë¦¬: {args.input}")
    cleaned_md = extract_images(args.input, args.output_dir)

    # ë³€í™˜ëœ MD ì €ì¥
    out_path = Path(args.output_dir) / Path(args.input).name
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(cleaned_md, encoding='utf-8')

    images_dir = Path(args.output_dir) / "images"
    image_count = len(list(images_dir.glob("*"))) if images_dir.exists() else 0

    print(f"\nğŸ“‚ ì´ë¯¸ì§€ ì¶”ì¶œ ê²°ê³¼:")
    print(f"  MD: {out_path}")
    print(f"  ì´ë¯¸ì§€: {image_count}ê°œ â†’ {images_dir}/")


def cmd_full(args):
    """ì „ì²´ ì²˜ë¦¬ (íƒ­ ë¶„í•  + ì´ë¯¸ì§€ ì¶”ì¶œ)"""
    out = Path(args.output_dir)
    out.mkdir(parents=True, exist_ok=True)

    # Step 1: íƒ­ ë¶„í• 
    if args.mcp_input:
        logger.info("=== Step 1: íƒ­ ë¶„í•  ===")
        content = parse_mcp_content(args.mcp_input)
        tabs = split_tabs(content)
        logger.info(f"ë°œê²¬ëœ íƒ­: {len(tabs)}ê°œ")
        saved = save_tabs(tabs, str(out / "tabs"))
        logger.info(f"íƒ­ íŒŒì¼ ì €ì¥: {len(saved)}ê°œ")
    else:
        logger.info("MCP ì…ë ¥ ì—†ìŒ â†’ íƒ­ ë¶„í•  ê±´ë„ˆëœ€")
        tabs = []

    # Step 2: ì´ë¯¸ì§€ ì¶”ì¶œ
    if args.md_input:
        logger.info("=== Step 2: ì´ë¯¸ì§€ ì¶”ì¶œ ===")
        cleaned_md = extract_images(args.md_input, str(out))
        md_out = out / Path(args.md_input).name
        md_out.write_text(cleaned_md, encoding='utf-8')
        logger.info(f"ë³€í™˜ëœ MD: {md_out}")
    else:
        logger.info("MD ì…ë ¥ ì—†ìŒ â†’ ì´ë¯¸ì§€ ì¶”ì¶œ ê±´ë„ˆëœ€")

    # ìš”ì•½
    print(f"\nğŸ“‚ ì²˜ë¦¬ ê²°ê³¼:")
    if tabs:
        print(f"  íƒ­: {len(tabs)}ê°œ â†’ {out / 'tabs'}/")
    images_dir = out / "images"
    if images_dir.exists():
        count = len(list(images_dir.glob("*")))
        print(f"  ì´ë¯¸ì§€: {count}ê°œ â†’ {images_dir}/")


def main():
    parser = argparse.ArgumentParser(
        description="Google Docs MD í›„ì²˜ë¦¬ê¸° (MCP + ì´ë¯¸ì§€ ì¶”ì¶œ)"
    )
    subparsers = parser.add_subparsers(dest='command', required=True)

    # split-tabs
    p_split = subparsers.add_parser(
        'split-tabs', help='MCP get_doc_content ê²°ê³¼ë¥¼ íƒ­ë³„ë¡œ ë¶„í• '
    )
    p_split.add_argument('--input', '-i', required=True, help='MCP ì¶œë ¥ íŒŒì¼ (JSON)')
    p_split.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_split.set_defaults(func=cmd_split_tabs)

    # extract-images
    p_img = subparsers.add_parser(
        'extract-images', help='Google MD ë‚´ë³´ë‚´ê¸°ì—ì„œ base64 ì´ë¯¸ì§€ ì¶”ì¶œ'
    )
    p_img.add_argument('--input', '-i', required=True, help='Google MD íŒŒì¼')
    p_img.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_img.set_defaults(func=cmd_extract_images)

    # full
    p_full = subparsers.add_parser(
        'full', help='íƒ­ ë¶„í•  + ì´ë¯¸ì§€ ì¶”ì¶œ ì „ì²´ ì²˜ë¦¬'
    )
    p_full.add_argument('--mcp-input', help='MCP ì¶œë ¥ íŒŒì¼ (JSON)')
    p_full.add_argument('--md-input', help='Google MD íŒŒì¼')
    p_full.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_full.set_defaults(func=cmd_full)

    args = parser.parse_args()
    args.func(args)


if __name__ == '__main__':
    main()
