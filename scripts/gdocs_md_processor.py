#!/usr/bin/env python3
"""
Google Docs MD í›„ì²˜ë¦¬ê¸° (v4)

Google Docsë¥¼ íƒ­ë³„ MD íŒŒì¼ë¡œ ìë™ ë³€í™˜:
  1. export: Google API ì§ì ‘ í˜¸ì¶œ â†’ íƒ­ë³„ MD ë‹¤ìš´ë¡œë“œ + ì´ë¯¸ì§€ ì¶”ì¶œ (ì™„ì „ ìë™)
  2. split-tabs: MCP get_doc_content ê²°ê³¼ ë¶„í•  (ìˆ˜ë™)
  3. extract-images: base64 ì¸ë¼ì¸ ì´ë¯¸ì§€ â†’ ë³„ë„ PNG íŒŒì¼ ì¶”ì¶œ (ìˆ˜ë™)

Usage:
  # ì™„ì „ ìë™í™”: ë¬¸ì„œ IDë§Œ ë„£ìœ¼ë©´ íƒ­ë³„ MD + ì´ë¯¸ì§€ ì¶”ì¶œ
  python gdocs_md_processor.py export DOC_ID --output-dir ./output

  # íŠ¹ì • ì´ë©”ì¼ ê³„ì • ì‚¬ìš©
  python gdocs_md_processor.py export DOC_ID --account jhkim2@goqual.com

  # íƒ­ ë¶„í•  (MCP get_doc_content ê²°ê³¼)
  python gdocs_md_processor.py split-tabs --input mcp_output.json --output-dir ./output

  # ì´ë¯¸ì§€ ì¶”ì¶œ (Google Docs ë„¤ì´í‹°ë¸Œ MD ë‚´ë³´ë‚´ê¸°)
  python gdocs_md_processor.py extract-images --input exported.md --output-dir ./output
"""

import argparse
import base64
import json
import logging
import os
import re
import sys
import time
import urllib.error
import urllib.parse
import urllib.request
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


@dataclass
class Tab:
    """Google Docs íƒ­ ì •ë³´"""
    name: str
    tab_id: Optional[str]
    depth: int  # ë“¤ì—¬ì“°ê¸° ê¹Šì´ (0=ìµœìƒìœ„)
    content: str
    line_start: int
    line_end: int

    @property
    def safe_filename(self) -> str:
        """íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¦„ ìƒì„±"""
        name = self.name.strip()
        # ìˆ«ì ì ‘ë‘ì‚¬ê°€ ìˆìœ¼ë©´ ìœ ì§€ (ì˜ˆ: "1. ì—°êµ¬ê°œë°œê³¼ì œì˜ ë°°ê²½")
        name = re.sub(r'[^\wê°€-í£\s\-\.]', '', name)
        name = re.sub(r'\s+', '-', name.strip())
        return name or "untitled"


@dataclass
class ExtractedImage:
    """ì¶”ì¶œëœ ì´ë¯¸ì§€ ì •ë³´"""
    ref_name: str       # image1, image2, ...
    format: str         # png, jpeg
    data: bytes
    filename: str       # output filename


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Google API Client: ì§ì ‘ API í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MCP_CREDS_DIR = Path.home() / ".google_workspace_mcp_work" / "credentials"
DOCS_API_BASE = "https://docs.google.com/document/d"
DOCS_REST_API = "https://docs.googleapis.com/v1/documents"


class GoogleDocsClient:
    """MCP credentialsë¥¼ ì¬í™œìš©í•˜ì—¬ Google Docs API ì§ì ‘ í˜¸ì¶œ"""

    def __init__(self, account: Optional[str] = None):
        self.creds = self._load_credentials(account)
        self.access_token = self._refresh_token()

    def _load_credentials(self, account: Optional[str]) -> Dict[str, Any]:
        if account:
            creds_path = MCP_CREDS_DIR / f"{account}.json"
        else:
            # ì²« ë²ˆì§¸ credentials íŒŒì¼ ì‚¬ìš©
            creds_files = list(MCP_CREDS_DIR.glob("*.json"))
            if not creds_files:
                logger.error(f"MCP credentials ì—†ìŒ: {MCP_CREDS_DIR}")
                sys.exit(1)
            creds_path = creds_files[0]
            logger.info(f"ê³„ì •: {creds_path.stem}")

        with open(creds_path, 'r') as f:
            return json.load(f)

    def _refresh_token(self) -> str:
        data = urllib.parse.urlencode({
            "client_id": self.creds["client_id"],
            "client_secret": self.creds["client_secret"],
            "refresh_token": self.creds["refresh_token"],
            "grant_type": "refresh_token",
        }).encode()
        req = urllib.request.Request(self.creds["token_uri"], data=data)
        with urllib.request.urlopen(req) as resp:
            token = json.loads(resp.read())["access_token"]
        logger.info("Google OAuth í† í° ê°±ì‹  ì™„ë£Œ")
        return token

    def _api_request(self, url: str) -> bytes:
        req = urllib.request.Request(
            url, headers={"Authorization": f"Bearer {self.access_token}"}
        )
        with urllib.request.urlopen(req) as resp:
            return resp.read()

    def get_tabs(self, doc_id: str) -> List[Dict[str, Any]]:
        """Docs APIë¡œ íƒ­ ëª©ë¡ ì¡°íšŒ (ID, ì œëª©)"""
        url = f"{DOCS_REST_API}/{doc_id}?fields=tabs"
        data = json.loads(self._api_request(url))
        tabs = []
        self._collect_tabs(data.get("tabs", []), tabs, depth=0)
        return tabs

    def _collect_tabs(
        self, tab_list: List[Dict], result: List[Dict], depth: int
    ):
        for tab in tab_list:
            props = tab.get("tabProperties", {})
            result.append({
                "tab_id": props.get("tabId", ""),
                "title": props.get("title", "Untitled"),
                "depth": depth,
            })
            children = tab.get("childTabs", [])
            if children:
                self._collect_tabs(children, result, depth + 1)

    def export_tab_as_md(self, doc_id: str, tab_id: str) -> str:
        """ê°œë³„ íƒ­ì„ Markdownìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        url = f"{DOCS_API_BASE}/{doc_id}/export?format=markdown&tab={tab_id}"
        return self._api_request(url).decode("utf-8")


def extract_images_from_content(
    content: str, images_dir: Path, prefix: str = ""
) -> str:
    """MD ë¬¸ìì—´ì—ì„œ base64 ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì°¸ì¡° ë³€í™˜ (íŒŒì¼ ê²½ë¡œ ë¶ˆí•„ìš”)"""
    images_dir.mkdir(parents=True, exist_ok=True)
    original_size = len(content)
    extracted: List[ExtractedImage] = []

    for match in IMAGE_DEF_PATTERN.finditer(content):
        ref_name = match.group('ref')
        fmt = match.group('fmt')
        raw_data = match.group('data').replace('\n', '').replace(' ', '')
        try:
            img_bytes = base64.b64decode(raw_data)
        except Exception as e:
            logger.warning(f"  {prefix}{ref_name} base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            continue

        filename = f"{prefix}{ref_name}.{fmt}" if prefix else f"{ref_name}.{fmt}"
        (images_dir / filename).write_bytes(img_bytes)
        extracted.append(ExtractedImage(
            ref_name=ref_name, format=fmt, data=img_bytes, filename=filename,
        ))
        logger.info(f"  {filename}: {len(img_bytes) / 1024:.1f} KB")

    cleaned = IMAGE_DEF_PATTERN.sub('', content)

    def replace_ref(m):
        alt = m.group('alt') or ''
        ref = m.group('ref')
        img = next((e for e in extracted if e.ref_name == ref), None)
        if img:
            label = alt if alt else ref
            return f"![{label}](images/{img.filename})"
        return m.group(0)

    cleaned = IMAGE_REF_PATTERN.sub(replace_ref, cleaned)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned).strip() + '\n'

    cleaned_size = len(cleaned)
    if original_size > 0 and original_size != cleaned_size:
        logger.info(
            f"  í¬ê¸°: {original_size / 1024:.0f}KB â†’ {cleaned_size / 1024:.0f}KB "
            f"({(1 - cleaned_size / original_size) * 100:.0f}% ê°ì†Œ)"
        )
    return cleaned


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MD Escape Cleaner: Google Docs ë¶ˆí•„ìš” ì´ìŠ¤ì¼€ì´í”„ ì •ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Google Docs MD exportê°€ ë¶ˆí•„ìš”í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„í•˜ëŠ” ë¬¸ìë“¤
# ì˜ˆ: \~ \< \> \+ \- \. \) \= \& \_ \* \[ \]
_GDOCS_UNESCAPE = re.compile(
    r'\\([~<>+\-.)=&_*\[\]])'
)


def clean_md_escapes(content: str) -> str:
    r"""Google Docs MD exportì˜ ë¶ˆí•„ìš”í•œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì •ë¦¬

    Google DocsëŠ” MD ë‚´ë³´ë‚´ê¸° ì‹œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³¼ë„í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„í•©ë‹ˆë‹¤:
      \~ â†’ ~  (ë¬¼ê²°í‘œ, ë‚ ì§œ ë²”ìœ„)
      \< â†’ <  (ë¹„êµ ë¶€í˜¸)
      \> â†’ >  (ë¹„êµ ë¶€í˜¸)
      \+ â†’ +  (ë”í•˜ê¸°)
      \- â†’ -  (í•˜ì´í”ˆ)
      \. â†’ .  (ë§ˆì¹¨í‘œ, í—¤ë”© ë²ˆí˜¸)
      \) â†’ )  (ë‹«ëŠ” ê´„í˜¸)
      \= â†’ =  (ë“±í˜¸)
      \& â†’ &  (ì•°í¼ìƒŒë“œ)
      \_ â†’ _  (ë°‘ì¤„)
      \* â†’ *  (ë³„í‘œ)
      \[ â†’ [  (ëŒ€ê´„í˜¸)
      \] â†’ ]  (ëŒ€ê´„í˜¸)
    """
    return _GDOCS_UNESCAPE.sub(r'\1', content)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tab Splitter: MCP get_doc_content ê²°ê³¼ ë¶„í• 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TAB_MARKER_PATTERN = re.compile(
    r'^--- TAB:\s*(?P<indent>\s*)(?P<name>.+?)'
    r'(?:\s*\(\s*ID:\s*(?P<tab_id>[^)]+)\s*\))?'
    r'\s*---$'
)


def parse_mcp_content(input_path: str) -> str:
    """MCP ì¶œë ¥ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (JSON ë˜ëŠ” plain text)"""
    with open(input_path, 'r', encoding='utf-8') as f:
        raw = f.read()

    # JSON í˜•ì‹ì¸ ê²½ìš°
    try:
        data = json.loads(raw)
        if isinstance(data, dict) and 'result' in data:
            return data['result']
        return str(data)
    except (json.JSONDecodeError, ValueError):
        return raw


def split_tabs(content: str) -> List[Tab]:
    """MCP get_doc_content ê²°ê³¼ë¥¼ íƒ­ ë‹¨ìœ„ë¡œ ë¶„í• """
    lines = content.split('\n')
    tabs: List[Tab] = []
    current_tab: Optional[dict] = None

    for i, line in enumerate(lines, 1):
        match = TAB_MARKER_PATTERN.match(line)
        if match:
            # ì´ì „ íƒ­ ë§ˆë¬´ë¦¬
            if current_tab:
                current_tab['line_end'] = i - 1
                tab_lines = lines[current_tab['line_start'] - 1:current_tab['line_end']]
                current_tab['content'] = '\n'.join(tab_lines)
                tabs.append(Tab(**current_tab))

            indent = match.group('indent') or ''
            depth = len(indent) // 4  # 4ì¹¸ ë“¤ì—¬ì“°ê¸° = 1 depth
            current_tab = {
                'name': match.group('name').strip(),
                'tab_id': match.group('tab_id'),
                'depth': depth,
                'line_start': i + 1,  # ë§ˆì»¤ ë‹¤ìŒ ì¤„ë¶€í„°
                'line_end': len(lines),
                'content': '',
            }

    # ë§ˆì§€ë§‰ íƒ­
    if current_tab:
        current_tab['line_end'] = len(lines)
        tab_lines = lines[current_tab['line_start'] - 1:current_tab['line_end']]
        current_tab['content'] = '\n'.join(tab_lines)
        tabs.append(Tab(**current_tab))

    return tabs


def save_tabs(tabs: List[Tab], output_dir: str) -> List[str]:
    """íƒ­ë³„ MD íŒŒì¼ ì €ì¥"""
    out = Path(output_dir)
    out.mkdir(parents=True, exist_ok=True)

    saved_files = []
    for idx, tab in enumerate(tabs):
        # íƒ­ ì´ë¦„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„± (ë²ˆí˜¸ ì ‘ë‘ì‚¬ë¡œ ì •ë ¬ ë³´ì¥)
        filename = f"{idx:02d}--{tab.safe_filename}.md"
        filepath = out / filename

        # MD í—¤ë” ì¶”ê°€
        header = f"# {tab.name}\n\n"
        if tab.tab_id:
            header += f"<!-- tab-id: {tab.tab_id} -->\n\n"

        content = header + tab.content.strip() + '\n'

        filepath.write_text(content, encoding='utf-8')
        saved_files.append(str(filepath))
        logger.info(
            f"  [{idx:02d}] {tab.name} "
            f"(depth={tab.depth}, lines={tab.line_end - tab.line_start + 1})"
        )

    return saved_files


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Image Extractor: base64 ì´ë¯¸ì§€ â†’ PNG íŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# base64 ì´ë¯¸ì§€ ì •ì˜: [imageN]: <data:image/png;base64,...>
IMAGE_DEF_PATTERN = re.compile(
    r'^\[(?P<ref>image\d+)\]:\s*<data:image/(?P<fmt>png|jpeg|jpg);base64,'
    r'(?P<data>[A-Za-z0-9+/=\s]+)>$',
    re.MULTILINE,
)

# ì´ë¯¸ì§€ ì°¸ì¡°: ![][imageN] ë˜ëŠ” ![alt text][imageN] (ì´ìŠ¤ì¼€ì´í”„ëœ \] í¬í•¨)
IMAGE_REF_PATTERN = re.compile(
    r'!\[(?P<alt>(?:[^\]\\]|\\.)*)\]\[(?P<ref>image\d+)\]'
)


def extract_images(md_path: str, output_dir: str) -> str:
    """Google Docs ë„¤ì´í‹°ë¸Œ MDì—ì„œ base64 ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì°¸ì¡° ë³€í™˜

    Returns:
        ë³€í™˜ëœ MD ë‚´ìš© (base64 â†’ íŒŒì¼ ê²½ë¡œ)
    """
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    images_dir = Path(output_dir) / "images"
    images_dir.mkdir(parents=True, exist_ok=True)

    original_size = len(content)
    extracted: List[ExtractedImage] = []

    # base64 ì´ë¯¸ì§€ ì •ì˜ ì°¾ê¸° ë° ì¶”ì¶œ
    for match in IMAGE_DEF_PATTERN.finditer(content):
        ref_name = match.group('ref')
        fmt = match.group('fmt')
        raw_data = match.group('data').replace('\n', '').replace(' ', '')

        try:
            img_bytes = base64.b64decode(raw_data)
        except Exception as e:
            logger.warning(f"  {ref_name} base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            continue

        filename = f"{ref_name}.{fmt}"
        img_path = images_dir / filename
        img_path.write_bytes(img_bytes)

        extracted.append(ExtractedImage(
            ref_name=ref_name,
            format=fmt,
            data=img_bytes,
            filename=filename,
        ))
        logger.info(
            f"  {ref_name}.{fmt}: {len(img_bytes) / 1024:.1f} KB"
        )

    # base64 ì •ì˜ ì œê±°
    cleaned = IMAGE_DEF_PATTERN.sub('', content)

    # ì°¸ì¡°ë¥¼ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜: ![alt][imageN] â†’ ![alt](images/imageN.png)
    def replace_ref(m):
        alt = m.group('alt') or ''
        ref = m.group('ref')
        img = next((e for e in extracted if e.ref_name == ref), None)
        if img:
            label = alt if alt else ref
            return f"![{label}](images/{img.filename})"
        return m.group(0)

    cleaned = IMAGE_REF_PATTERN.sub(replace_ref, cleaned)

    # í›„í–‰ ë¹ˆ ì¤„ ì •ë¦¬
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned).strip() + '\n'

    cleaned_size = len(cleaned)
    logger.info(
        f"  í¬ê¸°: {original_size / 1024:.0f}KB â†’ {cleaned_size / 1024:.0f}KB "
        f"({(1 - cleaned_size / original_size) * 100:.0f}% ê°ì†Œ)"
    )

    return cleaned


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_split_tabs(args):
    """íƒ­ ë¶„í•  ëª…ë ¹"""
    logger.info(f"MCP ì¶œë ¥ íŒŒì‹±: {args.input}")
    content = parse_mcp_content(args.input)
    tabs = split_tabs(content)
    logger.info(f"ë°œê²¬ëœ íƒ­: {len(tabs)}ê°œ")

    saved = save_tabs(tabs, args.output_dir)
    logger.info(f"ì €ì¥ ì™„ë£Œ: {len(saved)}ê°œ íŒŒì¼ â†’ {args.output_dir}")

    # ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“‚ íƒ­ ë¶„í•  ê²°ê³¼ ({len(tabs)}ê°œ íƒ­):")
    for idx, tab in enumerate(tabs):
        indent = "  " * tab.depth
        tid = f" ({tab.tab_id})" if tab.tab_id else ""
        print(f"  {indent}{idx:02d}. {tab.name}{tid}")


def cmd_extract_images(args):
    """ì´ë¯¸ì§€ ì¶”ì¶œ ëª…ë ¹"""
    logger.info(f"MD íŒŒì¼ ì²˜ë¦¬: {args.input}")
    cleaned_md = extract_images(args.input, args.output_dir)

    # ë³€í™˜ëœ MD ì €ì¥
    out_path = Path(args.output_dir) / Path(args.input).name
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(cleaned_md, encoding='utf-8')

    images_dir = Path(args.output_dir) / "images"
    image_count = len(list(images_dir.glob("*"))) if images_dir.exists() else 0

    print(f"\nğŸ“‚ ì´ë¯¸ì§€ ì¶”ì¶œ ê²°ê³¼:")
    print(f"  MD: {out_path}")
    print(f"  ì´ë¯¸ì§€: {image_count}ê°œ â†’ {images_dir}/")


def cmd_export(args):
    """ì™„ì „ ìë™í™”: ë¬¸ì„œ ID â†’ íƒ­ë³„ MD + ì´ë¯¸ì§€ ì¶”ì¶œ"""
    doc_id = args.doc_id
    max_depth = args.depth  # 0=ìƒìœ„ë§Œ, 1=1ë‹¨ê³„ í•˜ìœ„, 2=2ë‹¨ê³„ê¹Œì§€, -1=ì „ì²´
    out = Path(args.output_dir)
    out.mkdir(parents=True, exist_ok=True)
    images_dir = out / "images"

    # Step 1: Google API ì¸ì¦
    logger.info("=== Step 1: Google API ì¸ì¦ ===")
    client = GoogleDocsClient(account=args.account)

    # Step 2: íƒ­ ëª©ë¡ ì¡°íšŒ (í•˜ìœ„ íƒ­ í¬í•¨)
    logger.info("=== Step 2: íƒ­ ëª©ë¡ ì¡°íšŒ ===")
    all_tabs = client.get_tabs(doc_id)

    # depth í•„í„°ë§ (-1ì€ ì „ì²´)
    if max_depth >= 0:
        tabs = [t for t in all_tabs if t["depth"] <= max_depth]
    else:
        tabs = all_tabs

    logger.info(f"ì „ì²´ íƒ­: {len(all_tabs)}ê°œ, ë‚´ë³´ë‚´ê¸° ëŒ€ìƒ: {len(tabs)}ê°œ (depthâ‰¤{max_depth})")
    for t in all_tabs:
        indent = "  " * t["depth"]
        marker = "â†’" if t in tabs else "  (skip)"
        logger.info(f"  {indent}{t['title']} (depth={t['depth']}){marker}")

    # Step 3: íƒ­ë³„ MD ë‹¤ìš´ë¡œë“œ + ì´ë¯¸ì§€ ì¶”ì¶œ
    logger.info("=== Step 3: íƒ­ë³„ MD ë‹¤ìš´ë¡œë“œ ===")
    total_images = 0
    for idx, tab in enumerate(tabs):
        tab_title = tab["title"]
        tab_id = tab["tab_id"]
        depth = tab["depth"]
        safe_name = re.sub(r'[^\wê°€-í£\s\-\.]', '', tab_title)
        safe_name = re.sub(r'\s+', '-', safe_name.strip()) or "untitled"
        filename = f"{idx:02d}--{safe_name}.md"

        logger.info(f"  [{idx:02d}] {tab_title} (depth={depth}) ë‹¤ìš´ë¡œë“œ...")

        # Rate limit ëŒ€ì‘: 429 ì‹œ ìµœëŒ€ 3íšŒ ì¬ì‹œë„ (2ì´ˆ, 5ì´ˆ, 10ì´ˆ ëŒ€ê¸°)
        md_content = None
        for attempt, wait in enumerate([0, 2, 5, 10]):
            if wait > 0:
                logger.info(f"  [{idx:02d}] {wait}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt}/3)...")
                time.sleep(wait)
            try:
                md_content = client.export_tab_as_md(doc_id, tab_id)
                break
            except urllib.error.HTTPError as e:
                if e.code == 429 and attempt < 3:
                    continue
                logger.error(f"  [{idx:02d}] HTTP {e.code}: {e.reason}")
                break

        if md_content is None:
            continue

        # íƒ­ ê°„ ìš”ì²­ ê°„ê²© (rate limit ë°©ì§€)
        if idx < len(tabs) - 1:
            time.sleep(1)

        # ì´ë¯¸ì§€ ì¶”ì¶œ (íƒ­ë³„ prefixë¡œ ì¶©ëŒ ë°©ì§€)
        img_prefix = f"tab{idx:02d}-"
        cleaned = extract_images_from_content(md_content, images_dir, img_prefix)

        # ë¶ˆí•„ìš”í•œ ì´ìŠ¤ì¼€ì´í”„ ì •ë¦¬ (\~, \<, \., \- ë“±)
        cleaned = clean_md_escapes(cleaned)

        # íƒ­ ë©”íƒ€ ì£¼ì„ ì¶”ê°€ (depth ì •ë³´ í¬í•¨)
        header = f"<!-- tab-id: {tab_id} depth: {depth} -->\n\n"
        filepath = out / filename
        filepath.write_text(header + cleaned, encoding='utf-8')

        img_count = len(list(images_dir.glob(f"{img_prefix}*"))) if images_dir.exists() else 0
        total_images += img_count
        size_kb = len(cleaned) / 1024
        logger.info(f"  [{idx:02d}] {filename} ({size_kb:.1f}KB, ì´ë¯¸ì§€ {img_count}ê°œ)")

    # ìš”ì•½
    print(f"\nê²°ê³¼: {len(tabs)}ê°œ íƒ­ â†’ {out}/")
    print(f"  MD íŒŒì¼: {len(tabs)}ê°œ")
    if total_images > 0:
        print(f"  ì´ë¯¸ì§€: {total_images}ê°œ â†’ {images_dir}/")


def cmd_full(args):
    """ì „ì²´ ì²˜ë¦¬ (íƒ­ ë¶„í•  + ì´ë¯¸ì§€ ì¶”ì¶œ) - ë ˆê±°ì‹œ"""
    out = Path(args.output_dir)
    out.mkdir(parents=True, exist_ok=True)

    # Step 1: íƒ­ ë¶„í• 
    if args.mcp_input:
        logger.info("=== Step 1: íƒ­ ë¶„í•  ===")
        content = parse_mcp_content(args.mcp_input)
        tabs = split_tabs(content)
        logger.info(f"ë°œê²¬ëœ íƒ­: {len(tabs)}ê°œ")
        saved = save_tabs(tabs, str(out / "tabs"))
        logger.info(f"íƒ­ íŒŒì¼ ì €ì¥: {len(saved)}ê°œ")
    else:
        logger.info("MCP ì…ë ¥ ì—†ìŒ â†’ íƒ­ ë¶„í•  ê±´ë„ˆëœ€")
        tabs = []

    # Step 2: ì´ë¯¸ì§€ ì¶”ì¶œ
    if args.md_input:
        logger.info("=== Step 2: ì´ë¯¸ì§€ ì¶”ì¶œ ===")
        cleaned_md = extract_images(args.md_input, str(out))
        md_out = out / Path(args.md_input).name
        md_out.write_text(cleaned_md, encoding='utf-8')
        logger.info(f"ë³€í™˜ëœ MD: {md_out}")
    else:
        logger.info("MD ì…ë ¥ ì—†ìŒ â†’ ì´ë¯¸ì§€ ì¶”ì¶œ ê±´ë„ˆëœ€")

    # ìš”ì•½
    print(f"\nì²˜ë¦¬ ê²°ê³¼:")
    if tabs:
        print(f"  íƒ­: {len(tabs)}ê°œ â†’ {out / 'tabs'}/")
    images_dir = out / "images"
    if images_dir.exists():
        count = len(list(images_dir.glob("*")))
        print(f"  ì´ë¯¸ì§€: {count}ê°œ â†’ {images_dir}/")


def main():
    parser = argparse.ArgumentParser(
        description="Google Docs MD ë³€í™˜ê¸° (íƒ­ë³„ ìë™ ë‚´ë³´ë‚´ê¸° + ì´ë¯¸ì§€ ì¶”ì¶œ)"
    )
    subparsers = parser.add_subparsers(dest='command', required=True)

    # export (ì£¼ìš” ëª…ë ¹)
    p_export = subparsers.add_parser(
        'export', help='Google Docs â†’ íƒ­ë³„ MD ìë™ ë‚´ë³´ë‚´ê¸° (ì™„ì „ ìë™í™”)'
    )
    p_export.add_argument('doc_id', help='Google Docs ë¬¸ì„œ ID')
    p_export.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_export.add_argument('--account', '-a', help='Google ê³„ì • (ì˜ˆ: user@gmail.com)')
    p_export.add_argument(
        '--depth', '-d', type=int, default=-1,
        help='íƒ­ ê¹Šì´ ì œí•œ (0=ìƒìœ„ë§Œ, 1=1ë‹¨ê³„ í•˜ìœ„, -1=ì „ì²´, ê¸°ë³¸: -1)',
    )
    p_export.set_defaults(func=cmd_export)

    # split-tabs (ë ˆê±°ì‹œ)
    p_split = subparsers.add_parser(
        'split-tabs', help='MCP get_doc_content ê²°ê³¼ë¥¼ íƒ­ë³„ë¡œ ë¶„í• '
    )
    p_split.add_argument('--input', '-i', required=True, help='MCP ì¶œë ¥ íŒŒì¼ (JSON)')
    p_split.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_split.set_defaults(func=cmd_split_tabs)

    # extract-images (ë ˆê±°ì‹œ)
    p_img = subparsers.add_parser(
        'extract-images', help='Google MD ë‚´ë³´ë‚´ê¸°ì—ì„œ base64 ì´ë¯¸ì§€ ì¶”ì¶œ'
    )
    p_img.add_argument('--input', '-i', required=True, help='Google MD íŒŒì¼')
    p_img.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_img.set_defaults(func=cmd_extract_images)

    # full (ë ˆê±°ì‹œ)
    p_full = subparsers.add_parser(
        'full', help='íƒ­ ë¶„í•  + ì´ë¯¸ì§€ ì¶”ì¶œ (ë ˆê±°ì‹œ)'
    )
    p_full.add_argument('--mcp-input', help='MCP ì¶œë ¥ íŒŒì¼ (JSON)')
    p_full.add_argument('--md-input', help='Google MD íŒŒì¼')
    p_full.add_argument('--output-dir', '-o', default='./output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    p_full.set_defaults(func=cmd_full)

    args = parser.parse_args()
    args.func(args)


if __name__ == '__main__':
    main()
